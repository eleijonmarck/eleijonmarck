import { h as createVNode, F as Fragment } from './astro.98e1a385.mjs';
import 'html-escaper';
import 'cookie';
import 'kleur/colors';
import 'slash';
import 'path-to-regexp';
import 'mime';
import 'string-width';

const html = "<p><img src=\"/media/music-genre-classification.png\" alt=\"classification\"></p>\n<h1 id=\"---music-genre-classification\">‚ô´ - Music Genre Classification</h1>\n<p>Build a machine learning (ML) model that takes audio files as input and returns a corresponding music genre.</p>\n<h3 id=\"building-a-model-using-fastai-and--deploy-the-model-to-gcp\">Building a model using fastai and üöÄ Deploy the model to GCP</h3>\n<h2 id=\"gist-of-everything\">Gist of everything</h2>\n<ul>\n<li>\n<p>In <a href=\"#approach\">approach</a> lies all the steps taken</p>\n</li>\n<li>\n<p>this <a href=\"https://cloud.google.com/blog/products/ai-machine-learning/ai-in-depth-serving-a-pytorch-text-classifier-on-ai-platform-serving-using-custom-online-prediction\" target=\"_blank\" rel=\"nofollow\">cloud.google.article</a> contains all the information about the deploying pytorch on GCP.</p>\n</li>\n<li>\n<p>2 colab notebooks for creating data set and training model</p>\n</li>\n<li>\n<p>repo for deploying the model on GCP for GCE</p>\n</li>\n<li>\n<p>presentation given at Epidemic Sound 2019 <a href=\"https://docs.google.com/presentation/d/1WPgr9Y12DlzH3dkNjmi3Co77qIVgFOlim7SmEvzflX4/edit?usp=sharing\" target=\"_blank\" rel=\"nofollow\">music-genre-classfication</a></p>\n</li>\n<li>\n<p><a href=\"https://colab.research.google.com/drive/1CVMaHoJT_ECLADdRyyzqteVT-6oV-unb\" target=\"_blank\" rel=\"nofollow\">creating data set</a></p>\n</li>\n<li>\n<p><a href=\"https://colab.research.google.com/drive/1R4F85FIf0xdmEjeUm38WH4RhBgC_GGUf\" target=\"_blank\" rel=\"nofollow\">training model</a></p>\n</li>\n<li>\n<p>google app engine deployment repo is here <a href=\"https://github.com/eleijonmarck/music-genre-app-engine\" target=\"_blank\" rel=\"nofollow\">https://github.com/eleijonmarck/music-genre-app-engine</a></p>\n</li>\n</ul>\n<h2 id=\"approach\">Approach</h2>\n<h3 id=\"outcome-of-assignment\">Outcome of assignment</h3>\n<p><strong>Expected outcome</strong></p>\n<ul>\n<li>fastai library for model predictions</li>\n<li>serving the model in GCP w. their new custom prediction model function.</li>\n</ul>\n<p><strong>Actual outcome</strong></p>\n<ul>\n<li>trained fastai library for model predictions</li>\n<li>serving the model in GCP w. Google App Engine</li>\n</ul>\n<blockquote>\n<h2 id=\"outcome\">Outcome</h2>\n</blockquote>\n<p>Out of interest of time. The model is only trained on 2 classes <code>['classical', 'blues']</code></p>\n<p>app - <a href=\"https://momentum-project.appspot.com/\" target=\"_blank\" rel=\"nofollow\">https://momentum-project.appspot.com/</a></p>\n<p>upload - image from <code>docs/img_data/*</code></p>\n<p><img src=\"./media/end_result.png\" alt=\"final outcome\"></p>\n<hr>\n<h2 id=\"approach-1\">Approach</h2>\n<h3 id=\"training-the-model\">Training the model</h3>\n<ol start=\"0\">\n<li>Download data</li>\n<li>Find out research around the area of predicting music genre w. this particular data set.\n<ol>\n<li>Found out about MelSpectrograms for predicting the whole songs seems to be the silver standard (not cutting edge).</li>\n</ol>\n</li>\n<li>Using <a href=\"https://course.fast.ai/\" target=\"_blank\" rel=\"nofollow\">fastaiv3</a> for learning about the library of image classification and its approach to making a first model.</li>\n<li>Creating the data set for data augmentation / processing from raw audio file outputs to a Melspectrogram to represent the whole songs. (currently processed the blues, classical for interest of time) - colab: <a href=\"https://colab.research.google.com/drive/1CVMaHoJT_ECLADdRyyzqteVT-6oV-unb\" target=\"_blank\" rel=\"nofollow\">https://colab.research.google.com/drive/1CVMaHoJT_ECLADdRyyzqteVT-6oV-unb</a></li>\n<li>Train a image classifier using transfer learning w. ResNet as base - colab: <a href=\"https://colab.research.google.com/drive/1R4F85FIf0xdmEjeUm38WH4RhBgC_GGUf\" target=\"_blank\" rel=\"nofollow\">https://colab.research.google.com/drive/1R4F85FIf0xdmEjeUm38WH4RhBgC_GGUf</a></li>\n<li>Deploying model to GCP.\n<ol>\n<li>\n<p>Challenge here was that GCP does not natively support <code>pytorch</code> models. March GCP released custom prediction capabilities and wanted to get my hands dirty <a href=\"https://cloud.google.com/blog/products/ai-machine-learning/ai-in-depth-serving-a-pytorch-text-classifier-on-ai-platform-serving-using-custom-online-prediction\" target=\"_blank\" rel=\"nofollow\">Serving a PyTorch text classifier on AI Platform Serving using custom online prediction</a></p>\n</li>\n<li>\n<p>Challenge number 2 is that preprocessing can be dealt w. lambda functionality of the keras library. Hopefully we can make the preprocessing of the audio file into a image using the lambdas of keras. See <a href=\"https://towardsdatascience.com/writing-custom-keras-generators-fe815d992c5a\" target=\"_blank\" rel=\"nofollow\">preprocessing w. lambda keras</a></p>\n</li>\n<li>\n<p>Challenge number 3 is use case. What is the actual use case of this? Depending on that :</p>\n<p>Challenge number 2 might not even be relevant as we might only need this music-genre classification for post analytics. And therefore could postprocess data another way to skip the preprocessing directly from the api.</p>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"exact-steps-made-and-challenges-presented-on-the-way\">Exact steps made and challenges presented on the way</h2>\n<ol start=\"0\">\n<li>Download data set from <a href=\"http://opihi.cs.uvic.ca/sound/genres.tar.gz\" target=\"_blank\" rel=\"nofollow\">Download link</a></li>\n<li>Unzip the tar into your drive or an environment so you can pick it up from colab (as colab does not persist data)</li>\n<li>Creating the data set for training w. Melspectrograms. <a href=\"https://colab.research.google.com/drive/1CVMaHoJT_ECLADdRyyzqteVT-6oV-unb\" target=\"_blank\" rel=\"nofollow\">https://colab.research.google.com/drive/1CVMaHoJT_ECLADdRyyzqteVT-6oV-unb</a></li>\n<li>Training using the newly created <code>img_data</code> using fastai in colab\n<a href=\"https://colab.research.google.com/drive/1R4F85FIf0xdmEjeUm38WH4RhBgC_GGUf\" target=\"_blank\" rel=\"nofollow\">https://colab.research.google.com/drive/1R4F85FIf0xdmEjeUm38WH4RhBgC_GGUf</a></li>\n<li>deploy model using the newly created guide for <a href=\"https://cloud.google.com/blog/products/ai-machine-learning/ai-in-depth-serving-a-pytorch-text-classifier-on-ai-platform-serving-using-custom-online-prediction\" target=\"_blank\" rel=\"nofollow\">deploying pytorch models for gcp</a></li>\n<li>current step/progress, when trying to deploy the custom model prediction</li>\n</ol>\n<pre is:raw=\"\" class=\"astro-code\" style=\"background-color: #2e3440ff; overflow-x: auto;\"><code><span class=\"line\"><span style=\"color: #D8DEE9FF\">$ make create-model</span></span>\n<span class=\"line\"><span style=\"color: #D8DEE9FF\">OK</span></span>\n<span class=\"line\"><span style=\"color: #D8DEE9FF\">$ make create-version</span></span>\n<span class=\"line\"><span style=\"color: #D8DEE9FF\">gcloud alpha ai-platform versions create v2 --model music_genre_classification \\</span></span>\n<span class=\"line\"><span style=\"color: #D8DEE9FF\">\t--origin=gs://music-genre-classification/music-genre-v1.0.0/ \\</span></span>\n<span class=\"line\"><span style=\"color: #D8DEE9FF\">\t--python-version=3.5 \\</span></span>\n<span class=\"line\"><span style=\"color: #D8DEE9FF\">\t--runtime-version=1.13 \\</span></span>\n<span class=\"line\"><span style=\"color: #D8DEE9FF\">\t--package-uris=gs://music-genre-classification/python-prediction/music_genre_prediction-0.1.tar.gz \\</span></span>\n<span class=\"line\"><span style=\"color: #D8DEE9FF\">\t--machine-type=mls1-c4-m4 \\</span></span>\n<span class=\"line\"><span style=\"color: #D8DEE9FF\">\t--prediction-class=model.CustomModelPrediction</span></span>\n<span class=\"line\"><span style=\"color: #D8DEE9FF\">Creating version </span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9FF\">this might take a few minutes</span><span style=\"color: #ECEFF4\">)</span><span style=\"color: #D8DEE9FF\">......failed.</span></span>\n<span class=\"line\"><span style=\"color: #D8DEE9FF\">ERROR: </span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9FF\">gcloud.alpha.ai-platform.versions.create</span><span style=\"color: #ECEFF4\">)</span><span style=\"color: #D8DEE9FF\"> Create Version failed. Bad model detected with error:  </span><span style=\"color: #ECEFF4\">\"</span><span style=\"color: #A3BE8C\">Failed to load model: User-provided package music_genre_prediction-0.1.tar.gz failed to install: Command '['python-default', '-m', 'pip', 'install', '--target=/tmp/custom_lib', '--no-cache-dir', '-b', '/tmp/pip_builds', '/tmp/custom_code/music_genre_prediction-0.1.tar.gz']' returned non-zero exit status 1 (Error code: 0)</span><span style=\"color: #ECEFF4\">\"</span></span>\n<span class=\"line\"><span style=\"color: #D8DEE9FF\">make: </span><span style=\"color: #81A1C1\">***</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">[</span><span style=\"color: #D8DEE9FF\">Makefile:88: create-version</span><span style=\"color: #ECEFF4\">]</span><span style=\"color: #D8DEE9FF\"> Error 1</span></span></code></pre>\n<h2 id=\"new-approach-since-the-gcp-ai-platform-did-not-allow-for-deploying-pytorch-models\">New Approach since the GCP AI Platform did not allow for deploying Pytorch models</h2>\n<ol start=\"5\">\n<li>\n<p>Deploy on Google App Engine</p>\n</li>\n<li>\n<p>Following the <a href=\"https://course.fast.ai/deployment_google_app_engine.html\" target=\"_blank\" rel=\"nofollow\">fastai guide</a> on the fastai website.</p>\n<ol>\n<li>make a downloadable link of the model that you train</li>\n<li>deploy the app. Need to be EXACTLY the number of classes your are prediction w. the model. (This happened to be the cause of some unexplainable error)</li>\n</ol>\n</li>\n<li>\n<p>Deployed app is up and running @ <a href=\"https://momentum-project.appspot.com/\" target=\"_blank\" rel=\"nofollow\">https://momentum-project.appspot.com/</a></p>\n</li>\n<li>\n<p>Google App Engine does not allow requests to be built around cURL (c-language) requests. See <a href=\"https://stackoverflow.com/questions/2571627/curl-on-app-engine\" target=\"_blank\" rel=\"nofollow\">curl-on-app-engine</a></p>\n</li>\n<li>\n<p>Postman request instead <a href=\"https://www.getpostman.com/collections/c4a2cd9410835920354c\" target=\"_blank\" rel=\"nofollow\">https://www.getpostman.com/collections/c4a2cd9410835920354c</a></p>\n</li>\n</ol>\n<p>Would have taken some time to configura to setup <code>cURL</code> for GAE</p>\n<pre is:raw=\"\" class=\"astro-code\" style=\"background-color: #2e3440ff; overflow-x: auto;\"><code><span class=\"line\"><span style=\"color: #D8DEE9FF\">$ curl --request POST \\</span></span>\n<span class=\"line\"><span style=\"color: #81A1C1\">></span><span style=\"color: #D8DEE9FF\">   --url https://momentum-project.appspot.com/analyze \\</span></span>\n<span class=\"line\"><span style=\"color: #81A1C1\">></span><span style=\"color: #D8DEE9FF\">   --header </span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">Accept: */*</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #D8DEE9FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color: #81A1C1\">></span><span style=\"color: #D8DEE9FF\">   --header </span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">Accept-Encoding: gzip, deflate</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #D8DEE9FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color: #81A1C1\">></span><span style=\"color: #D8DEE9FF\">   --header </span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">Connection: keep-alive</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #D8DEE9FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color: #81A1C1\">></span><span style=\"color: #D8DEE9FF\">   --header </span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">Content-Length: 474050</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #D8DEE9FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color: #81A1C1\">></span><span style=\"color: #D8DEE9FF\">   --header </span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">Content-Type: multipart/form-data; boundary=--------------------------890612561901535102156936</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #D8DEE9FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color: #81A1C1\">></span><span style=\"color: #D8DEE9FF\">   --header </span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">Host: momentum-project.appspot.com</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #D8DEE9FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color: #81A1C1\">></span><span style=\"color: #D8DEE9FF\">   --header </span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">User-Agent: PostmanRuntime/7.19.0</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #D8DEE9FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color: #81A1C1\">></span><span style=\"color: #D8DEE9FF\">   --header </span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">content-type: multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #D8DEE9FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color: #81A1C1\">></span><span style=\"color: #D8DEE9FF\">   --form file=@/home/eleijonmarck/dev/epidemic-sound-ml-assignment/data/img_data/classical/classical00011.png</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #D8DEE9FF\">curl: </span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9FF\">92</span><span style=\"color: #ECEFF4\">)</span><span style=\"color: #D8DEE9FF\"> HTTP/2 stream 0 was not closed cleanly: PROTOCOL_ERROR </span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9FF\">err 1</span><span style=\"color: #ECEFF4\">)</span></span></code></pre>\n<h2 id=\"--data\">üìä  Data</h2>\n<p>As a dataset, use the (<a href=\"https://arxiv.org/abs/1306.1461\" target=\"_blank\" rel=\"nofollow\">in</a>)famous GTZAN Genre Collection dataset from</p>\n<blockquote>\n<p>Tzanetakis, George, and Perry Cook. ‚ÄúMusical genre classification of audio signals.‚Äù IEEE Transactions on speech and audio processing 10.5 (2002): 293-302.</p>\n</blockquote>\n<p><a href=\"http://opihi.cs.uvic.ca/sound/genres.tar.gz\" target=\"_blank\" rel=\"nofollow\">Download link</a> and <a href=\"http://marsyas.info/downloads/datasets.html\" target=\"_blank\" rel=\"nofollow\">homepage</a> for the dataset.</p>\n<h2 id=\"next-steps\">Next steps:</h2>\n<ul>\n<li>create baseline</li>\n<li>make preprocessing step for images</li>\n<li>create embeddings of the melspectrogram features for visualizing in t-SNE</li>\n<li>signal processing for melspectrograms to create MFCC features - <a href=\"https://www.youtube.com/watch?v=Z7YM-HAz-IY\" target=\"_blank\" rel=\"nofollow\">https://www.youtube.com/watch?v=Z7YM-HAz-IY</a></li>\n</ul>";

				const frontmatter = {"title":"‚ô´ -> „ÉÖ = hmm. Music Genre Classification","date":"2019-11-17T22:40:32.169Z","template":"post","draft":false,"slug":"music-genre-classification","category":"algorithms","tags":["deep-learning","audio"],"description":"Music Genre Classification using fastai and deploy on GCP","socialImage":"./images/music-genre-classification.png"};
				const file = "/Users/eleijonmarck/dev/eleijonmarck/better-bar/src/data/blog-posts/2019-11-17---music-genre-classification.md";
				const url = undefined;
				function rawContent() {
					return "\n![classification](/media/music-genre-classification.png)\n# ‚ô´ - Music Genre Classification\nBuild a machine learning (ML) model that takes audio files as input and returns a corresponding music genre.\n\n### Building a model using fastai and üöÄ Deploy the model to GCP\n\n## Gist of everything\n- In [approach](#approach) lies all the steps taken\n- this [cloud.google.article](https://cloud.google.com/blog/products/ai-machine-learning/ai-in-depth-serving-a-pytorch-text-classifier-on-ai-platform-serving-using-custom-online-prediction) contains all the information about the deploying pytorch on GCP.\n- 2 colab notebooks for creating data set and training model\n- repo for deploying the model on GCP for GCE\n- presentation given at Epidemic Sound 2019 [music-genre-classfication](https://docs.google.com/presentation/d/1WPgr9Y12DlzH3dkNjmi3Co77qIVgFOlim7SmEvzflX4/edit?usp=sharing)\n\n- [creating data set](https://colab.research.google.com/drive/1CVMaHoJT_ECLADdRyyzqteVT-6oV-unb)\n\n- [training model](https://colab.research.google.com/drive/1R4F85FIf0xdmEjeUm38WH4RhBgC_GGUf)\n\n- google app engine deployment repo is here https://github.com/eleijonmarck/music-genre-app-engine\n\n## Approach\n\n### Outcome of assignment\n**Expected outcome**\n- fastai library for model predictions\n- serving the model in GCP w. their new custom prediction model function.\n\n**Actual outcome**\n- trained fastai library for model predictions\n- serving the model in GCP w. Google App Engine\n\n> ## Outcome\n\nOut of interest of time. The model is only trained on 2 classes `['classical', 'blues']`\n\napp - https://momentum-project.appspot.com/\n\nupload - image from `docs/img_data/*`\n\n![final outcome](./media/end_result.png)\n\n---\n\n## Approach\n\n### Training the model\n0. Download data\n0. Find out research around the area of predicting music genre w. this particular data set.\n    1. Found out about MelSpectrograms for predicting the whole songs seems to be the silver standard (not cutting edge).\n1. Using [fastaiv3](https://course.fast.ai/) for learning about the library of image classification and its approach to making a first model.\n2. Creating the data set for data augmentation / processing from raw audio file outputs to a Melspectrogram to represent the whole songs. (currently processed the blues, classical for interest of time) - colab: https://colab.research.google.com/drive/1CVMaHoJT_ECLADdRyyzqteVT-6oV-unb\n3. Train a image classifier using transfer learning w. ResNet as base - colab: https://colab.research.google.com/drive/1R4F85FIf0xdmEjeUm38WH4RhBgC_GGUf\n4. Deploying model to GCP.\n    1. Challenge here was that GCP does not natively support `pytorch` models. March GCP released custom prediction capabilities and wanted to get my hands dirty [Serving a PyTorch text classifier on AI Platform Serving using custom online prediction](https://cloud.google.com/blog/products/ai-machine-learning/ai-in-depth-serving-a-pytorch-text-classifier-on-ai-platform-serving-using-custom-online-prediction)\n    2. Challenge number 2 is that preprocessing can be dealt w. lambda functionality of the keras library. Hopefully we can make the preprocessing of the audio file into a image using the lambdas of keras. See [preprocessing w. lambda keras](https://towardsdatascience.com/writing-custom-keras-generators-fe815d992c5a)\n    3. Challenge number 3 is use case. What is the actual use case of this? Depending on that :\n\n\t\tChallenge number 2 might not even be relevant as we might only need this music-genre classification for post analytics. And therefore could postprocess data another way to skip the preprocessing directly from the api.\n\n\n## Exact steps made and challenges presented on the way\n\n0. Download data set from [Download link](http://opihi.cs.uvic.ca/sound/genres.tar.gz)\n0. Unzip the tar into your drive or an environment so you can pick it up from colab (as colab does not persist data)\n1. Creating the data set for training w. Melspectrograms. https://colab.research.google.com/drive/1CVMaHoJT_ECLADdRyyzqteVT-6oV-unb\n2. Training using the newly created `img_data` using fastai in colab\nhttps://colab.research.google.com/drive/1R4F85FIf0xdmEjeUm38WH4RhBgC_GGUf\n3. deploy model using the newly created guide for [deploying pytorch models for gcp](https://cloud.google.com/blog/products/ai-machine-learning/ai-in-depth-serving-a-pytorch-text-classifier-on-ai-platform-serving-using-custom-online-prediction)\n4. current step/progress, when trying to deploy the custom model prediction\n\n```bash\n$ make create-model\nOK\n$ make create-version\ngcloud alpha ai-platform versions create v2 --model music_genre_classification \\\n\t--origin=gs://music-genre-classification/music-genre-v1.0.0/ \\\n\t--python-version=3.5 \\\n\t--runtime-version=1.13 \\\n\t--package-uris=gs://music-genre-classification/python-prediction/music_genre_prediction-0.1.tar.gz \\\n\t--machine-type=mls1-c4-m4 \\\n\t--prediction-class=model.CustomModelPrediction\nCreating version (this might take a few minutes)......failed.\nERROR: (gcloud.alpha.ai-platform.versions.create) Create Version failed. Bad model detected with error:  \"Failed to load model: User-provided package music_genre_prediction-0.1.tar.gz failed to install: Command '['python-default', '-m', 'pip', 'install', '--target=/tmp/custom_lib', '--no-cache-dir', '-b', '/tmp/pip_builds', '/tmp/custom_code/music_genre_prediction-0.1.tar.gz']' returned non-zero exit status 1 (Error code: 0)\"\nmake: *** [Makefile:88: create-version] Error 1\n```\n\n## New Approach since the GCP AI Platform did not allow for deploying Pytorch models\n5. Deploy on Google App Engine\n\n6. Following the [fastai guide](https://course.fast.ai/deployment_google_app_engine.html) on the fastai website.\n\t1. make a downloadable link of the model that you train\n\t3. deploy the app. Need to be EXACTLY the number of classes your are prediction w. the model. (This happened to be the cause of some unexplainable error)\n\n7. Deployed app is up and running @ https://momentum-project.appspot.com/\n8. Google App Engine does not allow requests to be built around cURL (c-language) requests. See [curl-on-app-engine](https://stackoverflow.com/questions/2571627/curl-on-app-engine)\n9. Postman request instead https://www.getpostman.com/collections/c4a2cd9410835920354c\n\n\nWould have taken some time to configura to setup `cURL` for GAE\n```bash\n$ curl --request POST \\\n>   --url https://momentum-project.appspot.com/analyze \\\n>   --header 'Accept: */*' \\\n>   --header 'Accept-Encoding: gzip, deflate' \\\n>   --header 'Connection: keep-alive' \\\n>   --header 'Content-Length: 474050' \\\n>   --header 'Content-Type: multipart/form-data; boundary=--------------------------890612561901535102156936' \\\n>   --header 'Host: momentum-project.appspot.com' \\\n>   --header 'User-Agent: PostmanRuntime/7.19.0' \\\n>   --header 'content-type: multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW' \\\n>   --form file=@/home/eleijonmarck/dev/epidemic-sound-ml-assignment/data/img_data/classical/classical00011.png\n\ncurl: (92) HTTP/2 stream 0 was not closed cleanly: PROTOCOL_ERROR (err 1)\n```\n\n## üìä  Data\nAs a dataset, use the ([in](https://arxiv.org/abs/1306.1461))famous GTZAN Genre Collection dataset from\n\n>Tzanetakis, George, and Perry Cook. \"Musical genre classification of audio signals.\" IEEE Transactions on speech and audio processing 10.5 (2002): 293-302.\n\n[Download link](http://opihi.cs.uvic.ca/sound/genres.tar.gz) and [homepage](http://marsyas.info/downloads/datasets.html) for the dataset.\n\n## Next steps:\n* create baseline\n* make preprocessing step for images\n* create embeddings of the melspectrogram features for visualizing in t-SNE\n* signal processing for melspectrograms to create MFCC features - https://www.youtube.com/watch?v=Z7YM-HAz-IY\n";
				}
				function compiledContent() {
					return html;
				}
				function getHeadings() {
					return [{"depth":1,"slug":"---music-genre-classification","text":"‚ô´ - Music Genre Classification"},{"depth":3,"slug":"building-a-model-using-fastai-and--deploy-the-model-to-gcp","text":"Building a model using fastai and üöÄ Deploy the model to GCP"},{"depth":2,"slug":"gist-of-everything","text":"Gist of everything"},{"depth":2,"slug":"approach","text":"Approach"},{"depth":3,"slug":"outcome-of-assignment","text":"Outcome of assignment"},{"depth":2,"slug":"outcome","text":"Outcome"},{"depth":2,"slug":"approach-1","text":"Approach"},{"depth":3,"slug":"training-the-model","text":"Training the model"},{"depth":2,"slug":"exact-steps-made-and-challenges-presented-on-the-way","text":"Exact steps made and challenges presented on the way"},{"depth":2,"slug":"new-approach-since-the-gcp-ai-platform-did-not-allow-for-deploying-pytorch-models","text":"New Approach since the GCP AI Platform did not allow for deploying Pytorch models"},{"depth":2,"slug":"--data","text":"üìä  Data"},{"depth":2,"slug":"next-steps","text":"Next steps:"}];
				}
				async function Content() {
					const { layout, ...content } = frontmatter;
					content.file = file;
					content.url = url;
					const contentFragment = createVNode(Fragment, { 'set:html': html });
					return contentFragment;
				}
				Content[Symbol.for('astro.needsHeadRendering')] = true;

export { Content, compiledContent, Content as default, file, frontmatter, getHeadings, rawContent, url };
