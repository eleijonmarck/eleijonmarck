{"data":{"tag":{"title":"optimization","belongsTo":{"edges":[{"node":{"title":"An Introduction to Gradient Descent w. Linear Regression","path":"/an-introduction-to-gradient-descent-w-linear-regression","date":"9. June 2019","timeToRead":7,"description":"Gradient descent is one of 'greatest hits' algorithms. This posts gives a detailed explained and walkthrough of why and how it is implemented and applied to an example for linear regression","cover_image":{"type":"image","mimeType":"image/gif","src":"/assets/static/gradient-descent-cover.1379a33.4b7a0b3.gif","size":{"width":512,"height":384},"sizes":"(max-width: 512px) 100vw, 512px","srcset":["/assets/static/gradient-descent-cover.a67b0b2.4b7a0b3.gif 480w","/assets/static/gradient-descent-cover.1379a33.4b7a0b3.gif 512w"],"dataUri":"data:image/svg+xml,%3csvg fill='none' viewBox='0 0 512 384' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-15'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='10'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-15)' width='512' height='384' xlink:href='data:image/gif%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAwCAIAAAAuKetIAAAACXBIWXMAAAPoAAAD6AG1e1JrAAAPS0lEQVRo3u2a%2b3MUV3bH9Wfkx/yQqvwN8W4ckt2sd7MuL35usL32mrAOxl47NrYpG5ussRE2gTUYjFmc2JinAfFGCBBIjIQeo%2bdII817NHrNaKZnpnt6puf9UD7dByYqvCChfVRtVW6puu70dN/7/Z7zPeeee0cNtb/w1vD/BGrzC9pfGAFBnMvlCoVCqVQql8t38PkzEGv4A9Enk8nZ2dlEIpG2mqqqmqYZhpG1Wp1YtVr9ExFrWDb6SqUSjUYVRQE0iPkIVjjoup7P53FLPB7nKz5yE4apVCpjNR4uFoslq92N2NK5NSwPPaaNWQ1Yc3NzWD1vNcABsWI1%2bjyG%2benzGB9hxTOQ4XmI8aT0hRWNb4UYrywxuhqWgR5tAJq5MXCEXjSqJpO6ZWrQYHixNB1sL8QgwFXI8BUekD4PMJoQ45m6FKWfud145o9DAPTgRPRcmSAcDoOSMDByeSxWLpXyhQJfYXgBRBNL8xh9kNFHddwU0BCmI2RAyR3xHiMIZ74VR93NCQ33lSvBge4lUiV2NZygxGOjQ%2blQIFeuICAmFuWIJAQQIPK3G%2b9KqAgZ%2bSgkJX5o4gdexCiFYpGh/iACvAwgJohEIoyL9BFO0mqR2ZmYkZ09/LuZjWvThqGl9LiigEYCF6p0sKKkJojdISEhWScmL3JlZPNdSOZzasLsL58AbxJVgBZrCQ3RKBJKgjKdCX/eGHz8Ae3016X5eSAArmBpCSigB9Mdlpa%2bEJNsewcx80Uy2/x85ErHxNFz2VqlVq0uhwDoMRJAQYwZMLwkR6630GtaZGYqtWfj5JpHEu//MmNvVQkIljZLBnV9CzgMAVbxhhBbGBv/RyyfVxOJfK2q%2byev/82KaFd/EfMvgwDoJUviUMYFMX1mikWjOAHoCbxhBkCf8dn65EdrU9te0Xe%2bro33p3OFjBXl8qIFNGGBzkt01tNr3epc66mWd%2bOanorNdD/w0xt/uyKRjLMwLkdCknBELd%2bVEB/Ds7OakdOHbcauNzL73zMONmZ2v1U4t6c45SnjOisDir4l7km0Cy0tcSJhULidvqCCcjKR6eD6F21/9dfTv92WLhZw6ZIIVK0mHafTKYixIrYHAR1ZernJ1XSCGWuaYWvKH/s4e/jj/KX92aad%2bdM7s1e/zivT6YwBxO/qW3L/QmJ1CaU0Fe9lp/2xD3/tfeIHzh9/L3H1QqZSRXmLEJAlHXuPj493dHSAz%2bPxMCIdbC%2bFAIhFstAwV19VjaGfmcls%2b9H82d1G2zEIZG6eyV47nGs7YtgvxPxO0GVuSSguSUayDQSET50YjXUwWyjm/I7UrvXRt5%2bdeW3V5EtPpqcnlKSay2aXRAB7AG56eppBg8HgzMwMQMXROEGx8iM0WHqhYUZCTEmFXNmes7lrh/T%2by5muM7q9WRtq0wZaDfv5uLNLnfazzJZKxZSWkgpPMpIErvTNUopEVCqntWRuuC1/8MP0Z2/pu9bHNjyT%2bOz9SrWCtIqLemDhaiUdh8MBE2bCYGbCsRIz88GQO1GraVpK8Toy9guATox0JBy2yPiA6rBN%2bd1Rpz0x1jPrHgqGQvEk%2bPVSsVCtUJbekhPN1H0qlc3lyf7JkMfoOZ8/tzvX9Gnu%2bPbM/k3qh2syN84WavOamuThJXlgamoKk3d1dWEbPCAFj0hoIQ2r/IlayVQJuwaTo51h99CUbzzsGg5OBENeDwQ8/mmfO0gnGAyMeWfHAtFQRI8oqaSmKwrFksH6Sk4iUSlzkWRgVO9vydqOG7bj2WsHc2d35459Yux7NxNykVMRcWGJMZC0ajKuMCYeJicn6xIyA0BRzGQaidSL0Mmp6ZDPPeca8vimQn6v0xfxByccPmXUO%2bfyzw77En1ulZvjgfCoP9rnidtdiX5PcsiXGPbGXBMJTzAS8E9MeUbjzu74SGfc0Znuu2R0nsxdP5Q7uSPf/KVZllareIwIuY80SqLgaZfLhRPgg6UhI%2bkI0KJaAmB6NuIORAKBIOiHfcqYL9zvUQc8yT6P2uvW20cNsHa7MtdG8tdHst3jKfNbrzboVQd9SYc/PuqH5IzfP%2bH3Bf1efOWJjvfHR27qA1eMzlO5C3uNEZtu5DLWJgkmixOQSpPk09raivqJYMGN7fGAuSaEwwmpfyJhXO%2baVB3eqDsw0%2bMCnHZzPN3uzHaOZ5qHinQuDZfOD5QvD%2bVbRwrNw%2bXTfZUzfeWLg4Wrw/m2UaPdmelwpm%2bO6d0uHYfAxOcNQiXiHlZGu1L2S7kbxwqaki%2bWyD9ksKUSQGpglRdQPDSkWuZmNBrjCy0eMyWkxN2Tmt2tOnzxXpd61VHoHDMuDpYAfcZePj9YPtZVbeqpNNmrhzvmD9qqJ3oqp%2b38VU/21vg7Za%2be6a9eGiq3jeY7xw2cY3cxlIInJ3xwcKj2lsxYV65YkuqD9LXUHZlEgkgoFAq53W4SH5q5tQFgIQt5I0GPOxTvcycHvKrdrV0YKDUPlS8OlI7eNJF91TZ/yFb7ur325bX5fZdrB9pr%2b1vn97bU%2bNt/tXqgvXrIVj3SWTneVTnZXTndWz7XX74yXLzhNHpc2rAv7vVPzXhGE4PXk%2bEpaluKboINI1bvUgjd6QHCJRAIkEAJABB7vV6iFvQ4gYFEUUrQFfB4RgMxtN48WGzqrQLiq7bagRvzX7bWPr9U23u5tuNMdU9zbfuZ2scnKzvOVHadr%2b26UNtxdp6/356rfXax9sUVk%2bEh2/xxk0YF1V1zFu1jCac3MuMeSc/4MtmcbGswP1MvyQNSNouEpAyGiehHwjdpJVHqn5npcL870TxYOtFTRdzYdXdz7XdX57c1VQG95dty44nKfx4s/eaQ%2bbfpm%2bI7/13YdKD4waHilmOVrScq/3Wq8uk5WFX3tJj%2bOdJRPdE73zqgJ5qPJDvPxyfcVsWVkC0bEsCUi%2byJZb8CPPGUHO8Q%2bwMDAwxB0ryd9eO3lgItNeCKXXEUz/aXv7lR3XHWNOq2psqmb0ofHC5v2J8H8Ztf5Nbvzb62K73%2b88ybe7Nv7s2t/zz79r78O18W3vu6%2bJvD5S3fVradgnl139X5ox2lueYTpYt7DHcv6xugmQ4jAh0yWHARD0jRT/XGm0NDQ9RCNpuN98lIohxZ80EvZRz1UTSmdLuzB221XRdrn5430W/Yn3v3fwqv78m8ukv/9af6i1vVFxsT//5x8leNiTWNCa5rt6kvb9de3Zl%2bY0/mrX1ZHt58uNR4ovZFc9nXO6D1XYr7x9AMgYvtwcOaXd8YLX4qge3RD536ARtvjoyMAFZWX7G9FEWMCIWZcKxlqPjFlXkkAXpM/vpuY01jcu0n6nPvRZ7fNPf0hpmnN8yu2jD9zLuzz24M/%2bK9yHPvz63eHH9xa3Lddg3PvLWv0PhtebxvLO7qC0yGZyJRWfWtpBeVAyUR85KOVXgIGlAHrpTpSIgrYzGuuXhZTbQ0MTGRTMRTeuacvfT%2bwQrCANDqD2IvbFaeeWf2qTcmH38t%2bOgr/pUv%2bx5d51%2b5zsff468Gn1o/uertaWis%2bUhZ/ZH64QHdPjJrLiYhTYmxzOtIAMRStMuWmhkRBUoWeIsHMU%2bTfAYHB4Hu9/utZcvcyDMotmd0olm0ZBpIZ5%2bZbOk33v2q9G9bkqs3x0AP6JXrvD95wfkvq50P/cLx0POOh54b/snq0Z%2buGX9krfuxVwNP/Edo1YbZxoPalcEMS3UgYoaZpqlyDCM1vHG7SUFwj%2bOthrudoIiExAzmLmxuTjxDSEhBKvORtHKGPhLIbj2SW7VRWflK8NF13h8/7/jnZwf/6Sn7Pz7Zu%2bKJnhVP9vxgVd8Pnx744TODD/1y5Ll3Qp8cy561l9qdpYlwJq7MWWdYZrGNvUCPZkQ/rEX9/f18pCyACVnxu05ouGMVAysLMGUpVoEAg96unM3w5b7kB0bHPLLBh0s%2bm4rMxY9dVl7eOvejF9wP/nzowce6v/%2bzjr9/xPb9h9u/93D7Aw/f%2bIfHuh/51dhLn8S3nyodtRUHvVnKBDVJjKmCWHZ8UsAzPqCHh4exI1OgC/rMvjgBKtDR0VHUDwEMIJsvqT3rWzOZQ4pt2YmTWHFFpWQktHxzp7Zx59S/vub50bNDDz5u/7uf9a74%2beDKl9xrt8xtPpA52pYb9hVSlGlZ3UpoiuRK2WPIIakce2Fv2XmjZKAj7N8bBg2/99BcOngAM8gouMVSqiY7WtkiyrEmNIQkrkjrWkqlr0YUY2BMv9QRb7qWuNJj2McLnkkjODmnmpIjflLmTkBRJGrl8FDOIWUKlMOM2J4tLgFJHEqNc68YqG%2bL4YoH5GXZE0s1IXCZo257ObAQy8khpkkspWfNM2qdbZauxYr5FH/5LPsqJZNOWbvKW%2bd2AtdMyuxxrN02jQd8Pp/YW/boLFBMsXgWEgKMG7IagLgyhHCQ4wNxdMo6kcXXskmQ1d7cJcdidRxmzMQT6YxhHc8RnWrC2i3V5ceAIj%2buDCLiIV0yo91uZzkDOulOgvg%2bjtclBQkZJIT7mEyONevHlxnrBFeUUz8XAYQcuUmT0xdRhRwJy0Ze5CeWlpLhtvxMVyCVmzdvcp/BccLY2BjjyAq7OIF6EIO7paWF7AtQ3MeahU8pKzAGtaosZwJXfh2T00IRlXgJHGJUkRyIwSTRWZcfjwl6Of6Xb7E6NwGD4ZAxyYdv7%2bMXGgiImaUgrZ9QwE0KQ2DBEBpMgIVgBTeoclMWb1wvvzjJrzUCUbWaLFJ0RH40%2bQlDdq2gJ1EymsQeaaevr4/RmEiW4fv4gUNUhBYZ8fr163L8JDWF7HWk3ToX0XUIMB%2bsJPpxGnyi1vkpIpZjQx6WnwAZSrwk58SiMZ5hEAlc7vA62Y8IlJO8Zf5GJieK5DJGkUUEkzA642InknTdRQsjR1hJ2kXB7OnI4qJmIEqRI%2bfSNCk8QQ/cnp4eXuQZXhG5LszpyyGwsPyQoz/wYQ8sDRnxLOEBE%2bYWyUmZJMTq7/IYQFELKHkRiCyUUnFhaVkuGUSyMCOAHtfhontsI5d6Ol0/673b7/KyAGFU6DEr%2biGHSLGEjoECMjmnkR8e5S2p2CEGbTjwFsQwP8SkfJBl649A4B6spC08igQN9pOPBMyU1YRMV1cXwrh8%2bTJw5RcDQbwwnGR9hLC4%2bs/3vxJ1JpJV6mtIvckCIjt0KcsEKBwQD95j99fd3S0VAP17HML9af9b5Y56vS6/hV6SekYSC1eRn6xWdeb3O%2b//AkNKGCFQav/fAAAAAElFTkSuQmCC' /%3e%3c/svg%3e"},"content":"<p>Gradient descent is one of those “greatest hits” algorithms that can offer a new perspective for solving problems. Unfortunately, it’s rarely taught in undergraduate computer science programs. In this post I’ll give an introduction to the gradient descent algorithm, and walk through an example that demonstrates how gradient descent can be used to solve machine learning problems such as linear regression.</p>\n<p>Gradient descent is <em><strong>widely</strong></em> used in Machine Learning and Deep Learning</p>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #81A1C1\">import</span><span style=\"color: #D8DEE9FF\"> pandas </span><span style=\"color: #81A1C1\">as</span><span style=\"color: #D8DEE9FF\"> pd</span>\n<span style=\"color: #81A1C1\">import</span><span style=\"color: #D8DEE9FF\"> numpy </span><span style=\"color: #81A1C1\">as</span><span style=\"color: #D8DEE9FF\"> np</span>\n<span style=\"color: #81A1C1\">import</span><span style=\"color: #D8DEE9FF\"> altair </span><span style=\"color: #81A1C1\">as</span><span style=\"color: #D8DEE9FF\"> alt</span>\n<span style=\"color: #D8DEE9FF\">data </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> pd.</span><span style=\"color: #88C0D0\">read_csv</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">demo.txt</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #ECEFF4\">)</span></code></pre>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #D8DEE9FF\">scatter </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> alt.</span><span style=\"color: #88C0D0\">Chart</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">data</span><span style=\"color: #ECEFF4\">)</span><span style=\"color: #D8DEE9FF\">.</span><span style=\"color: #88C0D0\">mark_circle</span><span style=\"color: #ECEFF4\">()</span><span style=\"color: #D8DEE9FF\">.</span><span style=\"color: #88C0D0\">encode</span><span style=\"color: #ECEFF4\">(</span>\n<span style=\"color: #88C0D0\">    </span><span style=\"color: #D8DEE9\">x</span><span style=\"color: #81A1C1\">=</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">x:Q</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #ECEFF4\">,</span>\n<span style=\"color: #88C0D0\">    </span><span style=\"color: #D8DEE9\">y</span><span style=\"color: #81A1C1\">=</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">y:Q</span><span style=\"color: #ECEFF4\">'</span>\n<span style=\"color: #ECEFF4\">)</span><span style=\"color: #D8DEE9FF\">.</span><span style=\"color: #88C0D0\">properties</span><span style=\"color: #ECEFF4\">(</span>\n<span style=\"color: #88C0D0\">    </span><span style=\"color: #D8DEE9\">title</span><span style=\"color: #81A1C1\">=</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">data</span><span style=\"color: #ECEFF4\">'</span>\n<span style=\"color: #ECEFF4\">)</span>\n<span style=\"color: #D8DEE9FF\">scatter</span></code></pre>\n<p><img class=\"g-image g-image--lazy g-image--loading\" src=\"data:image/svg+xml,%3csvg fill='none' viewBox='0 0 450 364' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-0'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-0)' width='450' height='364' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAA0CAYAAAA62j4JAAAACXBIWXMAAAsSAAALEgHS3X78AAAQX0lEQVRo3tVbC3hUxfW/dzeP3Q1sdpNsNpD3ZpMACY8EMFAekoIIiWgFW7WKKBUQpUIDJCRCIOEZIIi8hFZAHnmYBASCgKKClFoRBQqBPBaDSdVECvzBaq2133//vzPMrDfr3nzhEfF/v%2b98c3fOPXPOnDlzHjOJJP28HvnOcpcZfzkoKEg%2bduyY9Mknn0h1dXWsJTh//rzr3R0EztM3nvqWLFnCeCYkJGjQ5AJWgP9CwMT4%2bHiN0%2bmU1qxZ06axqK/OcV76xxeN0uvvfCRt2/tX6VJzI%2bvzRKd8/7k8sYCuvLXdKSFoJSIAfcxmc1R1dbURq%2b/vcDj8oSkXQHvUmnjr79Ya0Zr4t0Y3OvptUtLQ2I2NjUastjcHH4KGhgaj4Cu%2b5TxbjMn5MRxW2//vDReM%2b46cCCp/68Pgps8%2bNZ6qqjFxeYyKcZgs/LehpQY0mkg0g7t3755QWlqacvHixU61tbXh%2bDiMA72HAgYCIjCA6A/DO%2bFC0PYFdAV04t8LOsL1B8TgvTOnYbgTJ050rqqqSjp79mzSqVOnGJ1i7M5EQ7Q0hnJM4kG88N63ptYR4nR%2bF1iw9d1fzt7w5hin85vAf135gmgHkMxcPpesAJKhp0dTwCpoc3Nzw9VMBYSRreBISIMKjoTQquDMBCo4LdF6wp2rqTP889LnQVg%2bbeoftg9RurRhGUWDq6pro9VkhRJaziMmJoa1c%2bfO1RcUFLC9WFlZqQFzmQAEMhcoloTijkTmeI1ikib%2bLugEzgbQq%2bCsBFwwF0%2bO0xOtCs706YV6ppynFr3u73ReoQWUJhTs0o6dvzO0ts5BfkVCK7vzRNvS3yxYsIC1ixcv1sFLM82hlRUrIVq7YsKiTwhEJubPGQhNC1w03nVudOKbYAIVnI5olWMpxqY9HSZkTJ9VKj0%2bf4drThcu1LNVrXM4lCvvkqeFAiIjr1sEzN9lATt37iStSRwEoR2DaBX9klAI319CAbKSjjQO0Ctxigm5FOABpxerxVdRqq93TYKcGbOAQx%2bc1qBfgkVIB/58kn5rz1bXxRHu88ZPZQqLynGFVXn0AdgG4W3eOy1xqj6AK0ergjMTqOC0YpLuT12dw3DmXG0nNXmeLtj1iNQ506ctvkxGFKCBEpOSkmK2bNmSfO3atYCamhqrWB0OQSBMoYkCLIp%2b%2bo4cWS/utQPccPS7D1dCkNuYNPluHMzu/DgN0QaQnyC%2bDsd56yu7/hKAcBf1/VfNFHVMcIghACv2e/DXlz8PcP73csDxv50biD4LLCMYtMpxAwGJbomgTPtlRGxsbK/i4uKky5cv/%2bQKoEhAfSQsFziIO9Y%2bfAwrPLvV6fza//H5O59aUXw4dW3ZkV%2bhLxATNju/v2xy/u8V07Lth5Jy1h9IgyJ6kgLcJu9RAXd8C9xIGAwes6bj0IyizCcXvd5l6sq9A6nv7qnbklImv3o9lPXM8%2b3/3BbLxS8a2h7OQ0NDmXOYPXv2HXGCtEqM59vHNS8WH3ZFH%2bxxvYM7LApx9Dyat8OYOm17stP5bz%2bsPAufv5lbHjpqVumYR/Mq9C4f4Tgf6yaLuhNctGjRnQ6DFlc4yyrxSc8qHXF90l97C2ER65lDy1i1Xx4ybVvyyTPVpurauharPCq7lPF78%2bgpcp52JZ9Ww%2bCoUaNEIuRSwNq1a5UWIAawKxIYyW0lWyjADddCARfqP1EqLpgcGL2Pnl3W6b5ZpYkPzi5jk1267d2A5s8awlOefTUC/dMA5vtzSlmyNaFgd3LG6n2DBkzZ0un%2b7NIuyvkcO3lWo1SABwvwnCWeO3fOa/78%2bVGt7HObWilJOTago5rvAFOPIamx4UIgvDezAOxt6z3Ti/r8kNyUZP46t3wGJmkdmVny4PDpRZGwkFGWB9d0LHvzw4D3jp2OMD%2bwygwaFg6HzygaZPvterYNEC1srcyj5Rz1er0X5UMpKSkh69ati8d%2b8zp9%2bjQlIToBNAG0CVRJAXwVOD2P13Zuzl4KGsJ5oe3Cqzof7GkdQpMOk9ZjUjaEq%2biqc7XMlPM3Huw0buHrg7671kzySE8s2Jn%2b2/wdC%2bn9d0t22R/L35H4QM5rvwOMhoxyDU93yXnTmM8VVsZt2v1%2bR9QIlEIncJl1brKSfLEtFODt7W1E83h8fHzfsrKyAc3NzRGoBil/j%2bb7lyASMISHumgFzsYruF%2bg7QGI4Lm/wFEoG4y2C3lfMR6clA1mPBLboXdh0aFxmWv3j3R%2bezHM6fxP8PMv7n2saN8HiQ2f1sdjYgN//%2bLeYbl/ems4PP%2bSR/Iq5qwuO9KteP%2bx%2b6pr6gZCaff9%2bfiZriiJo5zffBmKNhJKjuGyRipl5bxJhmSPprFy5Uqf/Pz81sJH1M1Wg5ioxzCIhMZ08kyNpd%2bzr96dOP4VVzhEWEvA5AzvvP%2b3uLsmb07i4Y7x7zNpc%2bLD8yrydrx93A6Tt0nROdobkfVH4XzChAmsRQgkJ8j2zu7du8mRyKLq44Sx3NwlUSUqKiwKgybhbd1wNuxJV4j671fNUnWtQ%2bbFilU4wV%2b98FoKzDseji5uxMziEZOX7%2bkJR/jroRnb0wifte6A5jdzKwzY66OfW1E5svLwx92ub4Gr8tvvn5I/a7wg80pVK8xcIad6NZidnS3CYbuFwf9ca4ITnCjDk/dLyy5ihQs9DRfqLd9dbQqg9/GLd3nzUNgfCug9Zk7ZPWMX7Jw3fEbxMND1Rf8QhDrmMN/94LThmWV7HqR3bBfGZ9c7HwmZqHRuexgcN24caxEB2kUBWOEYSmTIw9MkqC9v40E2zsenq0P%2buPNovCIP6Iaw5jN46jZ/TLDzlBV7x2qHFXpj4r1HZpV4ie%2bw%2bgEbd/2FpbRHPjzD%2bMACbk4B4ikpKfFBMsTMA0WRMoNqSx7gygTdM0hyeE7nNz7YwwEPzy3XKXm%2b9uaHoVj5jCFTt3V/KLfcjJWe%2bPC8ch1WPblg67sWKM6UNGGTFduj%2b0Nzyn0VvsP45ecNoVTLYGz56EdVkuOHfMWVB4icxC2jdSmgAx0JGgwGmlTH9PR0I1a%2btWMvm1Kjbjg6M1TNA5C5uYTv9fRGA0LgQ4Oe3zocE/T7w6o3RktSmhZ96cOmFyW4fFPB7i7/vtoUCofYE7jU2LF/9P2hbvlOh6qw1y%2be2zLIgyzqNb%2bbg7wX0MPPz48GfiIuLq5/eXn5oKampmiEwVhu8gJo8kMBcYAY0U/OhsIbWjowTaIkg/qx6nbuNOn3kHpUfGer6%2bxXvvx7FAqVaOT9feDIJs3f9PYUVG85c195K3366n2L6SADocwG8x44ZUXls0u3HRoHJVlQ6VGII2fKxgQkYcUH4XsKbUIWO5ctjstqU86BWzD19W55OB/LHKbP%2bPHjOxQWFjLNvffee1q%2blxhwU6KBvcT5Gsdp%2bSpHiIMNSlL4eZzAxRw%2bdppZB8w8HgmNBWYfmDptW5fnV%2b4d63T%2bj2nw81vD4fT6Itab0HbFVuhPCRm2CDvBxWp7I2nSIDcQW5DK5wie9Wmvy%2bM6NyQZ47jMGgVoPRZDotJ6%2beWXfREJ2P6wWq2eTDlG7HlFn2jDkJgwH5CWVRIAGCy%2bQcYGH%2bDUcFxaWmbJ3XB2Q6VeeV7I3no9tXjXPYQbObPYF/hH75lRZODOUweLYZNEkuQui1GcCYqIonR2JKsH%2bSWPTnDy5MnicNQVBZATtOoEPRQ8YVgJ/%2bsla4U3JhggxkcIDH26YHeve2cW34/8fgRw4Shh/Qj3/VfNZmyBXw6YsjXxkXkVBuASkOQwHlXVdTpspWjuSGWlLPxMMMytxL5hJ8ieVatW3RYFiCggHhGe4K0jsl8%2b0BllbOiY3DKt0urQdoRPCFKGQZg/S3A%2bOHFWL4QVh6LtooC0NJZoSRs2bLilLUBXT%2bxHxCzWXGpqFJcYbM8hD7gbCY4r3Y15bEMAfEHm/iMnWTX32PwdLcZGHUBFV7SSj3ILKBRwa1tAnA0%2b%2beSTt%2bQExdGWu9MhYZD6GhDLfXjdn4gQZ5a6z9OiyElFLcAUUFPr0KKw0fz147Map/OfNI6BvLrieEyjSMRcTlDgFJcnN%2bYEUQ5TcjLabrcPrKiouKUwyKsuF46HrCG8PLWhVI18seTwKKStfVETdP7XlS96IkTeRbFZhDNOS/wSeFUXxfkIfDQPuQM5byXuxsNghw4dyPSMI0aMMC5dujTididCvAz2eCBy5lwtndwGqdD5qN1HEi/iqYJrcyLU4kES1C6pMO1jrLIOe957%2bfZDcta6/fKeQx%2b7jsQUV2Oy2xGcTvgADzjXzZDy4POmnODEiRNZm5%2bf327V4OXmRt97ZxTfi0KHxfiKg8fl23U3qJDh5oqhF154od3L4Xp2KDpWztlwQFxtST8bBSADlPikdeJe4HYfiIjr8X80Ncp0Za2YEN0eWd3ofnQ5ys1aiTMptoBGyHlTByLiWb16tU9eXl67HInRYaQKju79AlRwXmp/IMFDZMjNyPqjIzGdTkeC34dq8K72PBRVHlIKHL83FHeHNjd%2bXTitC0dj88KrB%2bcZpsAJ2hs7FPX19aWjqKh%2b/fqFrF%2b/vl2PxQHudOHi7pD3EZ3gZ%2bK0XnwsQevFedmVdBx8uYxtPxa/kxcjlAO0lgeoXcgSL%2bKpglPf554uRlJTU3/SqzG3ayrX5aiHeK5T1ALuBc%2bPiiFPeUCbrsbEX2/%2bf/0boVsOg2JQuh4X9wKkAFIMwfbt268fbtbV2Y8ePcoKCqTMDLdv3z6mEPq7wurqaqaA4uJiRvvGG28IOltVVZWeh1yG27Nnj8zpggnonfoIR9%2bw8wDQEC2901iEo7HpN/EinvROMhCOZKKHZCRZ6Z1kF/MQ8jgcjpYKiIqKErW5ZsGCBaph8NKlS6oHplevXg0BvccweOXKlXC6v/OE%2b/bbb80Ean%2bwQbQqOAPxvBlZKcp56rciDPZet25dMpRgxnawQmvBAuAcA6HBfitXrrQuXLjQIvqXLVtmnT59ugmr16uoqMiek5MTgGSK4bAi1qysLHNlZWXfTZs2hc%2bbNy%2bI%2bjE24YJnzJhhRv2RgAq0G71TnxiXvt28eXM40dIYNBb109jEA5ZgR7KWBDqTwBGQbCQjrCKFZBayEE/ISuOaDx482MOTAkzdunWzFRYWxiI1thAhERHQO%2bqE4FmzZiUgUQrBb4vAEYBBYHZ2dvycOXMiIUyQOw7jdYXQYaAL4n0Mt3z58kAIZAM%2bhr5T0tG34BcOuq747VIcV14Q8SKeWKwWOJINzjxk5syZiVCAReBEm5GR0Qm0Ua398TQdR3kKL5TJDQVYPODIvB8A2FXGHAYYoIIb2gruLvrjrVbkfIjyOA848kXp/N7DfQ5P8L9Q9/x0xGMymVjMnjZtmpybm0s3RtKkSZNkPz8/fzyMIf2eOnUqcyohISFePj4%2bnY1GI/MB48ePl2EpdMQmrVixgjLNIL1eb%2bQXsTL9ZepLL70kYXUls9ms64AHjonCsAQTlp555hk2rsFg6Ai6QKyYtHHjRonGpLG5nAYkcMH0fwd0vghrkTMzM2V6T05O1pCsFovFm1e7rL9Hjx4ab2/vYOD8fk7/JdKVr%2bad/8%2bR2zShG31oSwX/1ML%2bH2FP9PySBpZdAAAAAElFTkSuQmCC' /%3e%3c/svg%3e\" width=\"450\" alt=\"png\" data-srcset=\"/assets/static/output_4_0.9377235.f04b0e4.png 450w\" data-sizes=\"(max-width: 450px) 100vw, 450px\" data-src=\"/assets/static/output_4_0.9377235.f04b0e4.png\"><noscript><img class=\"g-image g-image--lazy g-image--loaded\" src=\"/assets/static/output_4_0.9377235.f04b0e4.png\" width=\"450\" alt=\"png\"></noscript></p>\n<h1 id=\"our-goal-is-to-align-a-line-to-this-dataset\"><a href=\"#our-goal-is-to-align-a-line-to-this-dataset\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Our goal is to align a line to this dataset</h1>\n<ul>\n<li>why would we want to do that?</li>\n<li>we can use this to infer properties of the dataset</li>\n<li>we can use it to predict future behaviour (extrapolate)</li>\n</ul>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #81A1C1\">from</span><span style=\"color: #D8DEE9FF\"> sklearn </span><span style=\"color: #81A1C1\">import</span><span style=\"color: #D8DEE9FF\"> linear_model</span>\n<span style=\"color: #81A1C1\">from</span><span style=\"color: #D8DEE9FF\"> sklearn </span><span style=\"color: #81A1C1\">import</span><span style=\"color: #D8DEE9FF\"> model_selection</span>\n<span style=\"color: #D8DEE9FF\">model </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> linear_model.</span><span style=\"color: #88C0D0\">LinearRegression</span><span style=\"color: #ECEFF4\">()</span>\n\n<span style=\"color: #D8DEE9FF\">X_train, X_test, y_train, y_test </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> model_selection.</span><span style=\"color: #88C0D0\">train_test_split</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">data</span><span style=\"color: #ECEFF4\">[</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">x</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #ECEFF4\">],</span><span style=\"color: #88C0D0\"> data</span><span style=\"color: #ECEFF4\">[</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">y</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #ECEFF4\">],</span><span style=\"color: #88C0D0\"> </span><span style=\"color: #D8DEE9\">test_size</span><span style=\"color: #81A1C1\">=</span><span style=\"color: #B48EAD\">0.2</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> </span><span style=\"color: #D8DEE9\">random_state</span><span style=\"color: #81A1C1\">=</span><span style=\"color: #B48EAD\">0</span><span style=\"color: #ECEFF4\">)</span>\n\n<span style=\"color: #D8DEE9FF\">model.</span><span style=\"color: #88C0D0\">fit</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">X_train.values.reshape</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #81A1C1\">-</span><span style=\"color: #B48EAD\">1</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> </span><span style=\"color: #B48EAD\">1</span><span style=\"color: #ECEFF4\">),</span><span style=\"color: #88C0D0\"> y_train</span><span style=\"color: #ECEFF4\">)</span>\n\n<span style=\"color: #4C566A\">#For retrieving the slope:</span>\n<span style=\"color: #88C0D0\">print</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #ECEFF4\">\"\"\"</span>\n<span style=\"color: #A3BE8C\">Model intercept (position of the line) </span><span style=\"color: #EBCB8B\">\\n{:.2f}</span>\n<span style=\"color: #A3BE8C\">Model coefficients (slope of the line) </span><span style=\"color: #EBCB8B\">\\n{:.2f}</span>\n<span style=\"color: #A3BE8C\">Model score (how close are we to fit a line to the data) </span><span style=\"color: #EBCB8B\">\\n{:.2f}</span>\n<span style=\"color: #ECEFF4\">\"\"\"</span><span style=\"color: #88C0D0\">.format</span><span style=\"color: #ECEFF4\">(</span>\n<span style=\"color: #88C0D0\">    model.intercept_</span><span style=\"color: #ECEFF4\">,</span>\n<span style=\"color: #88C0D0\">    model.coef_</span><span style=\"color: #ECEFF4\">[</span><span style=\"color: #B48EAD\">0</span><span style=\"color: #ECEFF4\">],</span>\n<span style=\"color: #88C0D0\">    model.score</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">X_test.values.reshape</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #81A1C1\">-</span><span style=\"color: #B48EAD\">1</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> </span><span style=\"color: #B48EAD\">1</span><span style=\"color: #ECEFF4\">),</span><span style=\"color: #88C0D0\"> y_test</span><span style=\"color: #ECEFF4\">)))</span></code></pre>\n<p>This gives us the intercept $b$ 6.69 (where the line should be centered around) and the coefficient of $m$ 1.35.\nWhich given our modeled loss function is a score of 0.27</p>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #81A1C1\">def</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">make_line_using</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9\">m</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #D8DEE9\">b</span><span style=\"color: #ECEFF4\">):</span>\n<span style=\"color: #D8DEE9FF\">    </span><span style=\"color: #4C566A\"># y = m * x + b</span>\n<span style=\"color: #D8DEE9FF\">    x </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> np.</span><span style=\"color: #88C0D0\">arange</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #B48EAD\">100</span><span style=\"color: #ECEFF4\">)</span>\n<span style=\"color: #D8DEE9FF\">    y </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> m </span><span style=\"color: #81A1C1\">*</span><span style=\"color: #D8DEE9FF\"> x </span><span style=\"color: #81A1C1\">+</span><span style=\"color: #D8DEE9FF\"> b</span>\n<span style=\"color: #D8DEE9FF\">    df </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> pd.</span><span style=\"color: #88C0D0\">DataFrame</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">np.matrix</span><span style=\"color: #ECEFF4\">([</span><span style=\"color: #88C0D0\">x,y</span><span style=\"color: #ECEFF4\">])</span><span style=\"color: #88C0D0\">.T</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> </span><span style=\"color: #D8DEE9\">columns</span><span style=\"color: #81A1C1\">=</span><span style=\"color: #ECEFF4\">[</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">x</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #88C0D0\">,</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">y</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #ECEFF4\">])</span>\n<span style=\"color: #D8DEE9FF\">    line </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> alt.</span><span style=\"color: #88C0D0\">Chart</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">df</span><span style=\"color: #ECEFF4\">)</span><span style=\"color: #D8DEE9FF\">.</span><span style=\"color: #88C0D0\">mark_line</span><span style=\"color: #ECEFF4\">()</span><span style=\"color: #D8DEE9FF\">.</span><span style=\"color: #88C0D0\">encode</span><span style=\"color: #ECEFF4\">(</span>\n<span style=\"color: #88C0D0\">        </span><span style=\"color: #D8DEE9\">x</span><span style=\"color: #81A1C1\">=</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">x:Q</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #ECEFF4\">,</span>\n<span style=\"color: #88C0D0\">        </span><span style=\"color: #D8DEE9\">y</span><span style=\"color: #81A1C1\">=</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">y:Q</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #ECEFF4\">,</span>\n<span style=\"color: #88C0D0\">        </span><span style=\"color: #D8DEE9\">tooltip</span><span style=\"color: #81A1C1\">=</span><span style=\"color: #ECEFF4\">[</span><span style=\"color: #88C0D0\">alt.Tooltip</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">y</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> </span><span style=\"color: #D8DEE9\">title</span><span style=\"color: #81A1C1\">=</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">b * x + m</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #ECEFF4\">)]</span>\n<span style=\"color: #88C0D0\">    </span><span style=\"color: #ECEFF4\">)</span><span style=\"color: #D8DEE9FF\">.</span><span style=\"color: #88C0D0\">interactive</span><span style=\"color: #ECEFF4\">()</span>\n<span style=\"color: #D8DEE9FF\">    </span><span style=\"color: #81A1C1\">return</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9FF\">scatter </span><span style=\"color: #81A1C1\">+</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9FF\">line</span><span style=\"color: #ECEFF4\">))</span>\n\n\n\n<span style=\"color: #D8DEE9FF\">m_guess </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> model.coef_</span><span style=\"color: #ECEFF4\">[</span><span style=\"color: #B48EAD\">0</span><span style=\"color: #ECEFF4\">]</span>\n<span style=\"color: #D8DEE9FF\">b_guess </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> model.intercept_</span>\n<span style=\"color: #88C0D0\">make_line_using</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">m_guess</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> b_guess</span><span style=\"color: #ECEFF4\">)</span></code></pre>\n<p><img class=\"g-image g-image--lazy g-image--loading\" src=\"data:image/svg+xml,%3csvg fill='none' viewBox='0 0 450 364' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-4'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-4)' width='450' height='364' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAA0CAYAAAA62j4JAAAACXBIWXMAAAsSAAALEgHS3X78AAARe0lEQVRo3tVbCVhURxKeCwYYOUZgYBAQhkvAIxM8wCgaDzww8VyN2SUac7jGAxRERUEQAUVRiUlMVBTkPuLBtazHZj2D0ShGzpkIiheecddETdzd2aqme/YxPNR80eC%2b7%2buve%2br1q66urq6/qhsEgpfrEXbu6EIyvtDGxkZ48uRJwYULFwQajYbUhuX7778nhbX5%2bnD7GtKSkpLImL6%2bviKoYqBsgPEToHzo5eUl0ul0gs2bNz8TL773XPm477RQrjZfFCSlHxLsP1b10qy8BxRvWqs6SwhcCWco/eVyuUt9fb0FrL6lVqu1BM2RAlrEYgVtC2xTmgXUVvSdBetHayuD33o69kXezc3NFrDaRrQYY7l06RJ5h32exMPgN5PJykAOIl8jtGvqNKTgGCnZXznsPXTavM0OEIlEDlAHgFn2ys/PH3Dz5k1lQ0ODEzBwhOIADN2gBEDbHooTtPGdPdT9oHhDUSINCvZ3hjIISjfsizwM6fR7pzNnzjhUV1era2pq1FVVVUoO7260rzP91pHyakOnYyqpDP2oTE60L7YDqus0nvduXrHT6e7ZrNy2f8rclJK36zXaXrymABoSx8TEOBnSgZkYmfLQUSFmPPTufPz56ECTY/mNPMxQFkP6uZp61lf4eljW6MAFmWr8cflSk3Objk5OrXNbuXKl6dq1a8leLCkpEQFTIR3AFAqhg1aRLqJ01LQVbQupw0FledC%2bQlr46IyHHRbGG99Rugd%2bQx2ZkI/Okc%2bKLdDNa82i7PJKceuC/mT/0fqSXmMjcydNXlGgZPPVar9v62/s7e0Jo6ioKFSAK7YzMzOJ4FQwE44ChGxgaoKWjM6ZhDttEw/MR%2bf0V2DhKIb1d2eKTtt7XPDtuTo2WXemPI5ScN8TBcRuPyBm81qYWjZt2sqiYPZ71Y6DEvqda0dbQBQbG%2btsSIcPJFCceUwP95%2bMpz/vAHx0oHXFwkN3eVYejY0XZA0arQP77ffhTqtB83aNTco4FPQs20gEGIyTexVwuEd6enrPR48eyWpra62oNzXHFYK6N9Rm1NysaNuHOi4ZBxlwT6vxOw6KtKNT3mbUwbrRNuuPfdRQy3%2b4cdk8v%2bKbrifP1lhx6dTLWzY1Nsqqaxu6X21u8sLJvLdm78D31%2bybCd7eTvfolntVdb0SlGPOeEORodNsi4MiEWoksFevXr45OTn%2bt27dUgIcOlFP64BmB2UgQwFacO/2p0pQcjw%2bemiut3fsgI78kd8rWGhbjwLY93xtg8s/bl1RhqWWTf/8y6Ov6nT3reHdYA46OJ09X99N99MNFUx08LwNJTPmbSgN/tf9FvvH/2yxqWvQDKLKdeAgCbb7PAkFHPlQAAfkodu9KBS423LZ0TNkq2zwgl1DGS1gbsbgLw%2be6m3Y992kvR6zkva%2bZzZ2k7XBdsFJi3nGbLud3dzceFGA46hMoag4zkyPAhiYcJwj1qisNijAR%2bcgiR4FkMbGhADG/a/HqiTTYgsxSMLFEQxbmNXlzHd1PfIqThox2YPCcwaC2U87VVVLJhUPjg5MnvFWIYIZIg%2bbi/5xcHAgg0ZHR5uuWbOm01AAnJkQzF7v7e%2b0NBOBy4%2bcFZymKPDo3nViRWOX5Fq%2bsTRv4tDQLF%2bM8K5dvkgs9Ke714QarR4eVSg7z5gdooA4Li7upUCB2noNb24Q9XnFiJGLsl8Zvig72Pfd7RZI%2b/pMjTmsupKHN/oKCQ%2b9u2EojB/79OnTxzUtLa3n48ePOwUFmhovWIIFWP7lyFkTWGkfcGQW4NwsD39zvissjlSn%2b8EYApuEP68rnqzT/Wim0z00O3bqvAW1RB8aEXLl601lN6c5S4cogCszGmBQnZeXR3KBF4EC3FwA4nFniMgwXicoACtof6flskP%2bX7/xfidhd%2biWoqPvZJZ%2brdb9%2b44tTL7LJwVHBofE704CSJwAv63BzB3r6jXO4CuUVIb%2bVCZ9LkBlxsDJgeUOT0SBGzduSMAR/q4oAIqQwyT0KDBwXobvyPDs8Oit%2bwcJfFdKBs3f5Q/Ob/rQ0MxhPd/drtQ9vOnQQS5gx2Pqz4YC3t6tFgFR4O%2bCAvhMXVmoFAxMMobJK76radAnMhNXFKhGLc4JgFU2X7vrK5NxS/PeAWf3NntfU6/xvNLcJKYHH0w%2bfS7AlQ9lRtmfigJBQUFMASYMBaAWcjw4ooCrIQpQ02YowLSLyZI7XV39GIdOnBOByRP6%2bKh8izeW5Q21n/wJngmY4mRfm5fRB%2bgEjyFrs1j6WcXEN5flzRoTmdsmJG5s9Rci7ph0bztykjImnytDAboIejrvFjh69KhRUlIS0U5GRkYbBTAPzh3gaTB463qz4NPCI1zP7ok1TH7EhOX5xGSnx30ZOjNxT/CYxTmRsNqjofjDpEfOXlccOnF5fs/gpbk9wCpkTDngKzwMkyHq4Jx4YLqNAjgL11YBEokEAwuVWq22TUlJ4cv7jTuI4vCAwtyAJmAxA3t6zNhqMmlFgTUzvaCIbHVQeLaK4nl08JK8CNqeHrwktwggbgxYhd63BIZm2gZF5JAIsL5B68YWhjMmIks3Pp%2bDsvPQXdqcxhobG%2bMk/gQoMKCgoGDw9evXXRsaGjyoB8V95AtlKGZouI%2bxIHPq7RHaXClSoHCeQB%2bOSoAV9/gZAhdITAZBKjoKvPrM0E2lf4TJKeJ3HhwZ%2belfRkCs/0pmWeXYkNW7I6dEF5ZPiSncsbngiP%2bB41Vvbcz5%2b8S9h077QazvpHtwE5HDjfL2pGO507HVVJbuTD4q61Aqu4rOxZ22/Xi3QFZWljQ5OZmY2uHDh8XUnJmXdeOcDolZoMHieLr30fwwaPJMzTtMwtdGaq74nPi2uies8lhwgF4ZpSck4N17wyT7QPYWDZ5/PChBBjG9MVhBPPiA6BkJe1zfXvWlFfLZWXxCgjWdvISOxZyxnAVqXPmoksxoFCji0PUWilGcHiZWr15tAj6A7A87OzsunEiZD2BHzQxmMMjhKvHSxUYhc3ZjInOk3aZ%2bSqwsvfiEGB0YNfV%2buLdHReQsBx%2bwaXpc0cdDwzL7gNOzAx/gDcp4LWHnwXE44dZHxZXFje19Ds2CwbSBfOgDpJx%2bAkMfgO7/VfYjPj5ejwIAh3onCHVHThBx1pLtfXz%2bfvI70fUrF117zdpuCpMJgYkSJ7Rtz3HJvZtX9HsP3r05enHOVFDAJDD75dCeMG5p7lhQQhdymvNxWTA4P%2bKPwGHi3tefFHFgWMA5EXLkc4Io%2b1OdIHtyc3ONfysKVBw9K374wzVnMG8lePt%2bXP7zN5bOAQ8/DCYfDtj%2bUf85O52SMg75tVy5ZN1/TroTbA2yncQjU8SQCFEhPxAA7mOi1E4Bzw0FpFIpbgPz4OBgC7CA7r8FBXS6nwUardaN48EVsLpvT44ukIMCIsDsF4ISFgYu2EVWGnxFrx37TnjAFpgB7/S2fvZ8nQdYxChBQKLEYEzV80QB8hgZGeEqhnh6egYUFhb%2bKhSAQlDgavNFFSQzDAWGQVLjDqvmpvvltlNYatnsabFFeQs2lu4MTS1bFL65PBaSGSXECIEfJu%2bL/TjvMMT3Pzg0NTW6aemYUA%2bHpMgPTN%2bdBj/udPLPHwUA/ggazpo1qwvEAapnRQF62UHMNjS1VJaYfkjy4O41cXWdpgcNdz1g/44Cc/8AApnF4AcCgpfmuUBM0HdKdEFfiAcGFe4/5ZxTfpKYJECfGJyo6PS5WjRfT3CCQoBRIcCfiCPLc0UBdg5A6i1btkgTExOfGQUw/MT0FdsAXSNh33elFw8q64kfI5xFQNkBUZ5fzPb9Yoju5vSdvdMMUOA18AMDsS9YjeL%2b7avWrYcd17hm6nbo63MingTnuaIAed5//31Sx8XF/SoUoKkuUUDUlgqhZ8hWInBWWeUA2OeJ45bkTQpelqOH2eKvvu0/fGGW%2b/jl%2bZbgIAORBmmtAlZYQdtc4bnOjpf%2b3FBg2bJlpP7iiy%2bkvwYFMAPDQwwuLzDv3qGbyt4DBfiB2esdE2yFwO17j/fH9ux1%2byQAcc40ucEDCwX3dolvoh0o5vmgAGUunjFjhgwU8MwogAcNx09XEwVIh28UBoXnDAfTfv3f91scIQCSvR6WaQPbAjzuHBGY/cjkzK8CeXjbAB8bHno7b//CUMDExARz5skeHh4Dn4YCeDeHqwBZmQvAXaDu8W3PtL3HA2YnF8/%2bJP/IKJ3uvgN68OaLja4Yw0NE98fSw2fUGP/fuHppCCYz%2bD3UntRrD4B6ABXW/Qne/sWhAH26DBs2rGtqauoTUeD65YtiSF7IsTRMXgHYPmrM4tzgD5L3kYOHogOnjEE5XobMs8srpUBHz46Xk1yPbM9udqkHb%2bft2YXsC0OBsLAwUldUVBgnJCS0QwH4QMru6iBZafXMvrFGf15XPBN%2bc8x6hgCyN9GPd646By7I7AZmr2BvIJoTMiUaHGbYYuHSOvL2LwwFVq1axS5GeFHgYlOjSV29Ri/8hKh8z9fDst4Ap%2baHR%2bnkBGnX34hQ%2bRXfiMEHOI1YlO0Bnr717E30EVsBdx4hubfDnYMCAH8CegyGCtCjQBONvw%2beOCeDSREnM35Z/ggoI8kW%2bPm2ovJMTVeqJNIX4noRntow3tFb93d0YdLuYqTTUIA9sP8xEOI90QVs7zdkQeY4iOv1%2b7umTuMISmqTC5w9X9/%2b0LGDkyKGAlg6GwXw%2bGkC5AL%2biAI3Wlpcvquu9cK0VvevO45x2w9MWJV2IAZi8z463T2H6roGL%2b0znAgxz8vo1IOrOF69O0WAzkUBSIbQq3fz9/e3RRRIoaHxos3lmNMHz0zcM%2bw/P94geyyj5Gujq81N7XIB7okQVQK77OSlv1QooD%2byqjxllJS4mphHcGSOK8Txk1%2bbt8ueHnGrWvOGx9zDiXYnQvT83Y3He7ehv1QoMGTIkNYTodhok4SktW6jIgv8xy3JHT01uohobP%2bxKogD/hcKc5xMuxMhnlvgp9E7HwUYc916geiDmK1vggLa3J3V1daYaDStt7VlZWXC8vJyIgD%2bLWFdXZ0lPU0izI8dOyaGvu70kFWYnJws4KMXFxcLKQ8FFpIsAQ3fkcQI%2buI32EYefHQ2JsqAspCrdJANZaR9VdXV1aY00xUyularbasAFxcX/fV4UkK8I9%2b1%2bd27d9vdF9y7d8%2bee37Pntu3b/MiCR/9wYMH8ocPH8p/Cw%2bUAWVp91cmIDOLU7hPS0uLMx9vO0ABv88%2b%2b%2bzV2PhEa0iK7CAmUMTGxtqkpaU5lZaW9luyZIkcVsNu3bp1dosWLbLat2%2bfGlbBDbLJrhA4KSCKtN24caM9aNp/9erV1vg9FqRv2LCB0CHossG%2bwEcREREh3717t09RUZHP4sWLkbcC32Ef7AsO2Q6/ZXyQJ6zwABwD6dgXx0YZUBaUCWVDGVHWkpKSfjt27HDCOeD3mzZtsoW2/MCBA735FGDl4%2bOjSklJ8Vi%2bfDlhDkpAgWyioqIcYSBvYEImhXQYyBr6eQLdBdu0ry0IaQf9fWNiYhQcHjgJQmcTQjoIah0ZGekRHR2tQt5IoxO1xb5AV%2bK3tK8t/FaAonriGEiHmEWxfv16a%2bjrAsWLKx%2b2QT5vlB3ngHRQijI8PFy5YsUKlyf98bQP/tWMAa0bPUI3fMZCecWAhoHHFNxZBnR3Sjf07MPx7NSAhrD8ByoL98F7jDcxcTOgoxcfzyPfG3jjzr0IpzL4djh7c3isrKxI9BQSEkKEVSqVRmZmZvKpU6cKt23bJqisrBQEBgYKjY2NlUAnkeCkSZOE9O%2bNJFKp1M7S0pLAz1tvvUXocrlcampqat2jRw/yPwELFy4UYt0FHplMhrfEgvnz5xOaWq0WQXBmC3QzJseePXsEffv2FQHN0tbWlmSjU6ZMIbyBryX0t8Fv4%2bPjBenp6YK5c%2bcKkQbvCEz/8ssvKIMxhDzIV/Yy/ZeIN2elhYL/s%2bd5CIxBkOL3Fvy/7ndS1fzZMnIAAAAASUVORK5CYII=' /%3e%3c/svg%3e\" width=\"450\" alt=\"png\" data-srcset=\"/assets/static/output_7_0.9377235.fb010ac.png 450w\" data-sizes=\"(max-width: 450px) 100vw, 450px\" data-src=\"/assets/static/output_7_0.9377235.fb010ac.png\"><noscript><img class=\"g-image g-image--lazy g-image--loaded\" src=\"/assets/static/output_7_0.9377235.fb010ac.png\" width=\"450\" alt=\"png\"></noscript></p>\n<h1 id=\"now-lets-try-to-implement-this-ourselves\"><a href=\"#now-lets-try-to-implement-this-ourselves\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Now let's try to implement this ourselves!</h1>\n<h3 id=\"naive-approach-to-guess-until-we-get-a-good-fit\"><a href=\"#naive-approach-to-guess-until-we-get-a-good-fit\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Naive approach to guess until we get a good fit</h3>\n<p>guessing the beta parameters linear equation</p>\n<p>$ y = m \\times \\mathbf{x} + b$</p>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #81A1C1\">def</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">plot_on_top_of_data</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9\">m</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #D8DEE9\">b</span><span style=\"color: #ECEFF4\">):</span>\n<span style=\"color: #D8DEE9FF\">    </span><span style=\"color: #4C566A\"># y = B_2 * x + B_1</span>\n<span style=\"color: #D8DEE9FF\">    x </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> np.</span><span style=\"color: #88C0D0\">arange</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #B48EAD\">100</span><span style=\"color: #ECEFF4\">)</span>\n<span style=\"color: #D8DEE9FF\">    y </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> b </span><span style=\"color: #81A1C1\">*</span><span style=\"color: #D8DEE9FF\"> x </span><span style=\"color: #81A1C1\">+</span><span style=\"color: #D8DEE9FF\"> m</span>\n<span style=\"color: #D8DEE9FF\">    df </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> pd.</span><span style=\"color: #88C0D0\">DataFrame</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">np.matrix</span><span style=\"color: #ECEFF4\">([</span><span style=\"color: #88C0D0\">x,y</span><span style=\"color: #ECEFF4\">])</span><span style=\"color: #88C0D0\">.T</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> </span><span style=\"color: #D8DEE9\">columns</span><span style=\"color: #81A1C1\">=</span><span style=\"color: #ECEFF4\">[</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">x</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #88C0D0\">,</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">y</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #ECEFF4\">])</span>\n<span style=\"color: #D8DEE9FF\">    line </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> alt.</span><span style=\"color: #88C0D0\">Chart</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">df</span><span style=\"color: #ECEFF4\">)</span><span style=\"color: #D8DEE9FF\">.</span><span style=\"color: #88C0D0\">mark_line</span><span style=\"color: #ECEFF4\">()</span><span style=\"color: #D8DEE9FF\">.</span><span style=\"color: #88C0D0\">encode</span><span style=\"color: #ECEFF4\">(</span>\n<span style=\"color: #88C0D0\">        </span><span style=\"color: #D8DEE9\">x</span><span style=\"color: #81A1C1\">=</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">x:Q</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #ECEFF4\">,</span>\n<span style=\"color: #88C0D0\">        </span><span style=\"color: #D8DEE9\">y</span><span style=\"color: #81A1C1\">=</span><span style=\"color: #ECEFF4\">'</span><span style=\"color: #A3BE8C\">y:Q</span><span style=\"color: #ECEFF4\">'</span>\n<span style=\"color: #88C0D0\">    </span><span style=\"color: #ECEFF4\">)</span>\n<span style=\"color: #D8DEE9FF\">    </span><span style=\"color: #81A1C1\">return</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9FF\">scatter </span><span style=\"color: #81A1C1\">+</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9FF\">line</span><span style=\"color: #ECEFF4\">))</span></code></pre>\n<p>Our guess</p>\n<p>$ y = 2 \\times \\mathbf{x} + 1$</p>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #D8DEE9FF\">m_guess </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #B48EAD\">2</span>\n<span style=\"color: #D8DEE9FF\">b_guess </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #B48EAD\">1</span>\n<span style=\"color: #88C0D0\">plot_on_top_of_data</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">m_guess</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> b_guess</span><span style=\"color: #ECEFF4\">)</span></code></pre>\n<p><img class=\"g-image g-image--lazy g-image--loading\" src=\"data:image/svg+xml,%3csvg fill='none' viewBox='0 0 450 364' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-5'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-5)' width='450' height='364' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAA0CAYAAAA62j4JAAAACXBIWXMAAAsSAAALEgHS3X78AAAS0UlEQVRo3tVbCVhV1fa/AzPKJNzLPFzuZZA0UXg4FEiYM5DmgL0MtbTMzAkHQAERFYcQJUXDnAVRwgGlcrbnnBoiCoLilGl%2balr/9D3rfff91maf%2b869HFKfWf3P963vnLPuPnuvvfZevzVskMn%2bWpf8zx1dzsaXOzs7y48dOya7ePGirLa2lt1N6cKFC4yEZ6k24ramvNmzZ7MxQ0JCFLilgXIw/kzQiMDAQIVer5fl5eU1yFB3QXbruyuy5ZsPyfYeOS377tplWV0TY4pluvCYNkR/lUsHCuZ3zZ8lBK2ENyjM0dHRt7q62g6rb19XV2cPjTGCxogc8GxHz5xnh7sD/81OaMfvDibvBj61pb6vXr1qh9U252RBdOXKFfYbtaG22AH2Vy/X263bcVT9j6/POJ2vrbMHOQr9CXLwdwcTOez4eIa2xOO/2xhrQKHwwS2yVatWIRs2bIi4deuW2/nz573Q2BPkjg/8QR3w7ArywjP95op7OCgY5EY8ELX3Br0E8qC21Icpn3/vderUKfeqqqrQs2fPhlZUVLgJfYPo25cwWR%2b9/pHTpMWfJxZsPhQGJdnXX7zYCWbgQ33ytm5chnAukxcfl547kOw0By4HtafnFyW3AgZQpqWleZny8YGSOpXgk0JsJPg%2bUv1L8cFzJDLl37l5zVP75jLblz9cEyXw2r%2b/KmLL3hOtJPqwIVkk%2bKQIpSkfSjCWw9/fn93T09Ot58yZw2yxrKxMgY/lvCNrkIZ/THyFaAAH/iznQEPK0vG2ck5SfKEPNZHQN/1Gz5fqL2qXbzlk0Se1uLn%2blzu0OLKuSetVxyvOtdTrHyq%2bPPiNTCSfg7BAJJuobw3JLpJPwccxxpusrCx2B0JbZWdn%2b9Ez7nJCTf6BFZ79BOFFA9O2sud8QeukIC1/lgl9NMXHdyoiifZavf5HNs7Q2ZtlOw9VMP63Vy9pTp%2btUYjH5HbuKZqoIJ8fyS70LeYbKcDHp2FHYPsbdkBpaamhI9ytBa3RAMIO4DZlL1IM3ZWiicpFbsmIL%2brboADYt/xcTa3A19acr1NmLN/JJnr5Uj3jV507HwBSPvrxpmEHcCD2Eila4Bt2wJXL9fLTVTWCAjRNYgDMwEvCZpTCACZ8SQxoZGO/wQePUL0RBkARflJ9vJ29ZaCsZZqZKQaQLE%2bKATAvb6M4CF7ADfcXQkND/VevXt32/v37TjU1NWq%2bOs58pcNATiA1JwKvNtxDOPG2LlwpEfw71WP4NPmWRASEWGVVRVWNGm7P6eEP37X56fZ1F3qHMtTXr1520esfND9ZWd0JO8MVu8UF36j42P5cFkdBPrwTP6yu7oI3vlHhW3uYj9OIuVvb4b2dSSAoJxTsrtPp2hQWFobeuXPn%2bSjg4sUI/Mb4JDxNmk%2b%2bJfl3IL/zxi%2bP%2bw7OKh2%2beNNXA1dsPRyMXWmr1/%2bfPdDfd0zujr7YyuH19RfVcIUuvG8jBQigCgU5Vp%2bv%2bxsm7Yk%2brHMK97d9d962d7CDOly5VP/Cn2ICUm7Q1AQ6fbA6%2bNUJ68cm538R6ffGUtuXRq8Ja/POp%2b4Mqwbl0%2bR8n9QNQnEuCzccsOo4anXH6LFrY1z7LWaAWGcqh4eHBwOHqVOn/iEgOG/dPiW5NbpqauvYFhdk6TN1oycUAFf3iMxS1nvKhpDYKRviRJPVkl1fu3JJjOoGEMRKG/Bh5qo9rwzMKBnUfWKh1kTpxvgya9asP8QNErILY8Ymb4gKeqvAGT7d7uc711sQb3XZYflrKcX2UECr2zevGq30yPnbBN%2buFfl59htMwg5KNADb69M22XcZv77blPwv3kASxVZ9QHqJAtgi7QZjY2OFQMiggMWLFxspQNCaENzw50YK4MGMlq%2buTFjp7QdOKfGu45N/8bXUYibwjgOnvL45U63uMmH9CPBfHphZwlB79ILt/dEmqOfkomCT1dMKO/D2jauMd%2bybs476X%2b8wVxqfUhwRl7zhteAhBU56/c/quzevWTaYwy%2b09aUVYHA9586ZzZgxQ8rGLJpwYZQnNDfhNY60/uvamGK6JhWGvTJuHRM4LqV4Tp%2bpxUO6Tlgf3WNSUVSvyUXxIUML7JH8BODZDeFvC%2bCCU7ekwnBqD2DzN01noWRFXvFXYS%2bPXtMD2z1U4FeePe8Hj2EhIbfxHK2trclufCIiIlyXLFkSiA7NKisrKfy14pOnUDMIdzMKLDgmEDBqORITn3aJJWVaoBD6DgGLtV7/b/NxC3eoPsgp08D/BtF4w%2bduDQMaB9LzmzNK30uYXjJy467j5gPSN3WMSy6egnsnyOAu7J7MFbtdxi7coSGQhlsLwcRsDxyrZAHOtE92Wr43b1vf8Xnlb09e8jkLy785U2Oz61CFOeQI4mGyBZeP5DYD6YwUYG5ubkeyBAYGhm/cuLHTzZs3vZENamjb08rzjiI56Gk4UYbXEffWIG/O8%2bMuqTN9hy2v%2bee9G14ApoislbujVm07PAwTGYCJ2M1YubtL0sflr%2br/dbtl0efHumESPd6aWZrdP23TTCB3OGy330fr98eW7v66za8/3fRAP55wlb5Y0Vfu3foWWeIPrrlF%2b3tDkUPzS/7RG3FDO/DdoHQtl4WCoEi%2bcDQHPx4a%2b%2bDeVtIEcnNzLTIzM6WyPrOnyQYbbTF%2bfV1xTgd31BXujeFGUOInfqvLjngh3A3zHZTvSmYRNuJTs5hx6xInflw%2bGu%2b%2b8i7zrY23%2bwNV2Lsrm0WPXfcqqKNgApVna9ybiATNHuumhw8fzu5wgQSCzH63bt2qkHKDHOTEbtAoGxRMQ9z/sNlb5AhwzOo5H3YfA3cXiInGYwt3/2BB2fsdRq0O5CDmBSxIxOoaXN/4ReWGcDZ9%2bc7XAY594lM2GFznqcpqR3EuIM76SHbTDLQRRiUnJwvu8JndYG1tnQJ2quU%2bPLzXlCImwKETVQpEer4iN%2biG9Lbb3zM/S4SvngZg7In2sSAP%2bj0pr7xHn9SNPqL2HgC4uIzlu%2bIFHsJaxe%2bSDSYmJrI7PMAzK2Dr3pNK2KN31Ji1rpjMAMaMmS9fX35UWfzl8XayqDlKrLIdJqSVaVOVCG/bvzd/W5fID9do4L48BZnWbj/C4nXd4GVyeINo9NWj9dvLAao/upftP6mUNRuDrf9Q2OrPpgDhKioqskAwxLYHkiLJOMAklTWKBLmdK298e1kT/t5K675TNxpleYjFJ/aYVBiGyURjsjFwcf4rth6iqM8eIe%2bL/dI2qkS27gZADMHkX2fK4ldV9fmAer6V6yTSYfECcVC2EgVljRTQjEqCNjY21GHzXr162WHlpcpWFk2Us6h219wYpO5SOdtfeMdOUGPrjo1PLfZdANTGRDV4T2g7YgXzz3PW7A1dvuWQLvLDtfGIANkqth2xsjkCoWGYfJJ7/yWWPL4TFkNTXVNrKkdzkkUq9yDZJfgGU%2bwGam1ra0uDvBUQENBh06ZNL9%2b4ccMPblDHw04CkhAQuTZf8qFEvHMqcoYSH5MmHgUpAaAYCliQwmr%2bdf%2bG96xVe2JhrynpBTuzx%2bRuH48QdTK2ryuyvY6jcsrS4fbigeRW%2bp%2b/95qxYnfCO3O2JiJCHPTLjzd9kCJrEEDpeARIBY4YUACNxfMCPy4DyeIjyMdl7cxl1/C5aPlzO%2bPivI7FBRbDhg1r9tFHHzETOHDggJIjvpBt%2bYsKpEq%2bGt7iTI4CF6yOGfw/Q3SAmx/I8/VpG937pBYnbNlzoh1WNRjvLyZklGgAgtG7Dld4nDl3XtV5zFo3tOkPswmjb%2bH3ffccPm1%2b4vQ5OdJXBUd3GZ%2b8mTgp42m1t6l8XEk23DspRHyNaSjJ7vn5%2bZbwBMw%2b1Gq12G9ainIBceLjCZtkGICJRcHHM5cIJeg4rzNi%2bb/DrXWC63IBBrxJfPDC4B260vNXx8%2bosd37dh67tgts3VYYEwGPFrtKLuHD/QW8EfHoDMDTVD6OAZbiMF0SBEeOHCkURw1eADGBXJTJSYIgKYAOL7j/dkLezYIOrFpQt4mF8QC7REy0Zbt3VzLNz1%2b3Lw7uLhwTdYdCnAkPEMlRCBtuiEnmGFybVpR2iyfVKBvk6bCnFAiS7L8FguxatGjR/6QAcTYoXD/dvq4gm0WQ44dJGgEkQlU/QVlQznQAXwfE9a7I1CgUl60pOyLX//uuzDTtfe4K6NmzJ7svW7bsqU2AjpvoGavJeIs3faVEnO6OMFWHrd5aFMj0mb16TzTSXnJtffDOagDXrlxyPn22Rs0zvd/c6s/NBITa4JAhQ54aBIVTHaEcDZMwq6%2b/qOufvskM6G4OwGNKALh1RsKTgtU3OpaqazjCchX13QjshMOY5waCSIdpm/TVarUvlZSUPLEb5K4nlLsiLXeDOoTCXc4i90eAo567dl8CQO6dKUu%2bGHSysronIjlXZHU6gFwAz8wiOPnwPppyd8/PDTZr1oy2lF337t3t5s6d6/0sgdDQWZsVP3x/zaeh8LE%2bAGDYPWb8OhZ4fH/9ilSxxZlIgq8RbPxx/GcJhIwuBEFPFQrzdJOBYPaavYrgIQWsfdm%2bk20Q8sbBzmOGZW9m227ltsNmFCzRM3aA%2bFRHfDQmbwrspPgiMP6fQ%2bGGrGrEiIbKS2bmUyVDBDzI/oy8AGy8w7hFOxJ7TCzsBaRnuylkaIHiu2uXn/psUGTjkvzf7WwwNTX1idNhDj6sI0Rw3khxmQnEJRd7APXjKZJDNshMYND0EjPRtvvrKgARoIxP2ko4FzAtiAjIiZWUlx84pRQOHvYdrXRBEhMZl1LcE36/Ga8G64QI88Tpajmv4SuFWpxJLMFOmiR2l45/Y6R0Uz7nOYhM4OkLIsKVl5dnMX36dMmSmNTJ0KTFn3cckL4pITDxE68nKYk1carjRPSkQPU0J0NPXBKzsrKiul5vZIN/ExdFuYthRVEAV2eAmDfV2rfsPdFmyKzNA3MK909A3N8ark2FnIBid0NRlH8nFCL9eADTWShQCoVLfuYYJiq4CoXYzvwbcR9GfN6eErLWvEDrKSraevFC7uOLopaWlua4%2bbZv39516dKlhrJ4PeznbHWtxfGKc06P7t%2bgsjS5ucg3Mj9LgGtT6fU/uV29ckm1ff8pC6SthBOWPPAI4eV0K05G5XLOE0rrwt8FKTlPKMWH8G8shX5M%2bTxEN%2bM4ohX64KV7M14RfnxZ/HEHI3Qt/exgh6gxa3t2n1jYRuBVVNV4YdWf6GCkKX5TcQBfRdmT8Olwhg5ppLa6VBzQyESjo6MbHY29n7WKAZ1DXJ4SOX23D3O3J3oOWMIQdVXZEQFMPIU4QOpozATtjfgiRGZH5eIDVqk4QIov9gLiZEgEsE/mBTDphrJ49iyrrNlzDOUs%2bPEgrPhrI%2bZubaXX32cgk5z/hfLbq5fkomTouf2N0B/mBuvr6xtQPXW6Tf78DI%2bI8dtsYqcUxfaeUhQluLPKqmom/O4vy%2bU7ysuZAPS3hNXV1fa8oMo6P3jwoLK2tuEMcN26dXKE1jIp/rZt2%2bS8DxURPROPfmsor9dq6Rt6pj6k%2bMKYJAPJQs/lkG3Hjh1CW01VVZU1d/VygV9XV2esAF/f/74Pn7Y0OmZiSfeopFKDa/pVrze/e/eup6kt3bt3D7m8vtHJ0O3btyX/QEKK/%2bDBA8eHDx86PksfJAPJYsqHzF50nmjKJy8n1bda5%2b8XOiPnk5jMGTOd1uZMsc%2bcPc81I2O684pPP/Xavn17%2bOTJkx2xGup58%2bapx48f74BgKRSr4J%2bcnOyEAEo1c%2bZMlwULFrhC0%2b2zsrJawLRURMTPyclhfITbztQW/aiSkpIcS0tLWyIDbTlx4kTqW0W/URtqu3DhQjV9K/RDfWKFI2gM4lNbGptkIFlIJpKNZCRZy8rKwlesWOGVkZHhTN/n5ua64Nlx165draUU4BAS8oLm49y5mqmpKS6zsuepkRiRQM4pKSmeGCgYnbBJER8DtUAIHQC%2bLz3zti4QUo32IWlpaWwyAh/fMb4wIeJD0BaTJk3STZs2TUN9E49P1IXagu9G3/K2LnhXQVEv0BjER%2biumj9/fgu09QUFiuWjZ8gXTLLTHIgPpbhNmDDBberUqb6/9cfTLemvZkx49N5Voi2VktqY8Mjt9CPLMuFrOd%2b0yhNDf6dswqO4pD%2bXRXxR0TSOn2eIL8KqeAn56C8/Ooreg7kMIU3OvjkuBwcH5jsHDx7MhHVzczO3sbFxHDBggLygoEB29OhRWWRkpNzCwsINfBYH9O3bl7V1d3c3Q2Cltre3Z6WohIQExnd0dLS0trZuERQUxP4nYNy4cXK6N8Nla2tLfzkuGz16NOOFhoYqEJ26gG8jyLF582ZZWFiYAjx7FxcXUpCsX79%2bcl7QsUd7Z/oWcYxs1apVslGjRsmJh99Yye7Ro0ckg4W5uTn1a/tX%2bi%2bRYNFKy2X/z67fQ2AXkOqPFvw/lus17KYJkvYAAAAASUVORK5CYII=' /%3e%3c/svg%3e\" width=\"450\" alt=\"png\" data-srcset=\"/assets/static/output_11_0.9377235.4a663e8.png 450w\" data-sizes=\"(max-width: 450px) 100vw, 450px\" data-src=\"/assets/static/output_11_0.9377235.4a663e8.png\"><noscript><img class=\"g-image g-image--lazy g-image--loaded\" src=\"/assets/static/output_11_0.9377235.4a663e8.png\" width=\"450\" alt=\"png\"></noscript></p>\n<h4 id=\"not-the-most-sufficient-algorithm-but-might-work\"><a href=\"#not-the-most-sufficient-algorithm-but-might-work\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Not the most sufficient algorithm but might work.</h4>\n<p>hmmmmmm ¯\\<em>(ツ)</em>/¯\nlet's think of another approach.</p>\n<blockquote>\n<p>Can we we somehow see if we have a good guess?</p>\n</blockquote>\n<h1 id=\"lets-improve-our-guessing-strategy-using-gradient-descent\"><a href=\"#lets-improve-our-guessing-strategy-using-gradient-descent\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Let's improve our guessing strategy using Gradient Descent</h1>\n<p><strong>Gradient descent</strong> is an optimization algorithm used to <strong>minimize some function (loss function)</strong> by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model. Parameters refer to coefficients in Linear Regression and weights in neural networks.</p>\n<p><img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/gradient_descent.png\" alt=\"landscape\"></p>\n<p>Starting at the top of the mountain, we take our first step downhill in the direction specified by the negative gradient.\nWe continue this process iteratively until we get to the bottom of our graph, or to a point where we can no longer move downhill–a local minimum.</p>\n<p><img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/gradient_descent_demystified.png\" alt=\"winner\"></p>\n<p><a href=\"https://math.stackexchange.com/a/1695446/196117\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">math.stackexchange - Partial derivative in gradient descent</a></p>\n<p><a href=\"https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">ml-cheatsheet</a></p>\n<h2 id=\"lets-introduce-the-loss-function-or-costerror\"><a href=\"#lets-introduce-the-loss-function-or-costerror\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Let's introduce the loss function (or cost/error)</h2>\n<p>A Loss Functions tells us “how good” our model is at making predictions for a given set of parameters. The loss function has its own curve and its own gradients. The slope of this curve tells us how to update our parameters to make the model more accurate.</p>\n<p>${\\displaystyle \\operatorname {MSE} ={\\frac {1}{n}}\\sum <em>{i=1}^{n}(Y</em>{i}-{\\hat {Y_{i}}})^{2}.}$</p>\n<p>Given ${\\displaystyle n}$ predictions generated to ${\\hat{Y}}$, and ${\\displaystyle Y}$ is the vector of observed values of the variable being predicted.</p>\n<hr>\n<p>Our example with\n$ \\hat{Y} = mx_i + b$</p>\n<p>Now let’s run gradient descent using our new loss function. There are two parameters in our lost function we can control: m (weight) and b (bias). </p>\n<p>Since we need to consider the impact each one has on the final prediction, we need to use partial derivatives. We calculate the partial derivatives of the loss function with respect to each parameter and store the results in a gradient.</p>\n<p>Given the loss function:</p>\n<p>$$\nf(m,b) =  \\frac{1}{N} \\sum_{i=1}^{n} (y_i - (mx_i + b))^2\n$$</p>\n<p>The gradient can be calculated as:</p>\n<p>$$\nf'(m,b) =\n\\begin{bmatrix}\n\\frac{df}{dm}\\\n\\frac{df}{db}\\</p>\n<code class=\"shiki\" style=\"background: #2e3440; color: #d8dee9\">\\end{bmatrix}</code>\n<p>=\n\\begin{bmatrix}\n\\frac{1}{N} \\sum -2x_i(y_i - (mx_i + b)) \\\n\\frac{1}{N} \\sum -2(y_i - (mx_i + b)) \\\n\\end{bmatrix}\n$$</p>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #81A1C1\">def</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">step_gradient</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9\">m</span><span style=\"color: #ECEFF4\">:</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">int</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #D8DEE9\">b</span><span style=\"color: #ECEFF4\">:</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">int</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #D8DEE9\">points</span><span style=\"color: #ECEFF4\">:</span><span style=\"color: #D8DEE9FF\"> np.ndarray</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #D8DEE9\">learning_rate</span><span style=\"color: #ECEFF4\">:</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">float</span><span style=\"color: #ECEFF4\">)</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">-&gt;</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">list</span><span style=\"color: #ECEFF4\">:</span>\n<span style=\"color: #D8DEE9FF\">    </span><span style=\"color: #ECEFF4\">\"\"\"</span>\n<span style=\"color: #A3BE8C\">    this calculates the gradient step of a **linear function**</span>\n<span style=\"color: #A3BE8C\">    WILL NOT WORK for multiple dimensional data,</span>\n<span style=\"color: #A3BE8C\">    since the derivates will be on matricies instead</span>\n<span style=\"color: #A3BE8C\">    </span><span style=\"color: #ECEFF4\">\"\"\"</span>\n<span style=\"color: #D8DEE9FF\">    b_gradient </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #B48EAD\">0</span>\n<span style=\"color: #D8DEE9FF\">    m_gradient </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #B48EAD\">0</span>\n<span style=\"color: #D8DEE9FF\">    N </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">float</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">len</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">points</span><span style=\"color: #ECEFF4\">))</span>\n<span style=\"color: #D8DEE9FF\">    </span><span style=\"color: #81A1C1\">for</span><span style=\"color: #D8DEE9FF\"> i </span><span style=\"color: #81A1C1\">in</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">range</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #B48EAD\">0</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> len</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">points</span><span style=\"color: #ECEFF4\">))</span><span style=\"color: #D8DEE9FF\">:</span>\n<span style=\"color: #D8DEE9FF\">        x </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> points</span><span style=\"color: #ECEFF4\">[</span><span style=\"color: #D8DEE9FF\">i, </span><span style=\"color: #B48EAD\">0</span><span style=\"color: #ECEFF4\">]</span>\n<span style=\"color: #D8DEE9FF\">        y </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> points</span><span style=\"color: #ECEFF4\">[</span><span style=\"color: #D8DEE9FF\">i, </span><span style=\"color: #B48EAD\">1</span><span style=\"color: #ECEFF4\">]</span>\n<span style=\"color: #D8DEE9FF\">        b_gradient </span><span style=\"color: #81A1C1\">+=</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #81A1C1\">-</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #B48EAD\">2</span><span style=\"color: #81A1C1\">/</span><span style=\"color: #D8DEE9FF\">N</span><span style=\"color: #ECEFF4\">)</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #81A1C1\">*</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9FF\">y </span><span style=\"color: #81A1C1\">-</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">((</span><span style=\"color: #D8DEE9FF\">m </span><span style=\"color: #81A1C1\">*</span><span style=\"color: #D8DEE9FF\"> x</span><span style=\"color: #ECEFF4\">)</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #81A1C1\">+</span><span style=\"color: #D8DEE9FF\"> b</span><span style=\"color: #ECEFF4\">))</span>\n<span style=\"color: #D8DEE9FF\">        m_gradient </span><span style=\"color: #81A1C1\">+=</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #81A1C1\">-</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #B48EAD\">2</span><span style=\"color: #81A1C1\">/</span><span style=\"color: #D8DEE9FF\">N</span><span style=\"color: #ECEFF4\">)</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #81A1C1\">*</span><span style=\"color: #D8DEE9FF\"> x </span><span style=\"color: #81A1C1\">*</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9FF\">y </span><span style=\"color: #81A1C1\">-</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">((</span><span style=\"color: #D8DEE9FF\">m </span><span style=\"color: #81A1C1\">*</span><span style=\"color: #D8DEE9FF\"> x</span><span style=\"color: #ECEFF4\">)</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #81A1C1\">+</span><span style=\"color: #D8DEE9FF\"> b</span><span style=\"color: #ECEFF4\">))</span>\n<span style=\"color: #D8DEE9FF\">    b </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> b </span><span style=\"color: #81A1C1\">-</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9FF\">learning_rate </span><span style=\"color: #81A1C1\">*</span><span style=\"color: #D8DEE9FF\"> b_gradient</span><span style=\"color: #ECEFF4\">)</span>\n<span style=\"color: #D8DEE9FF\">    m </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> m </span><span style=\"color: #81A1C1\">-</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9FF\">learning_rate </span><span style=\"color: #81A1C1\">*</span><span style=\"color: #D8DEE9FF\"> m_gradient</span><span style=\"color: #ECEFF4\">)</span>\n<span style=\"color: #D8DEE9FF\">    </span><span style=\"color: #81A1C1\">return</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">[</span><span style=\"color: #D8DEE9FF\">b, m</span><span style=\"color: #ECEFF4\">]</span></code></pre>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #D8DEE9FF\">new_b, new_m </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">step_gradient</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">m_guess</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> b_guess</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> data.values</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> learning_rate</span><span style=\"color: #ECEFF4\">)</span>\n<span style=\"color: #D8DEE9FF\">new_b, new_m</span></code></pre>\n<code class=\"shiki\" style=\"background: #2e3440; color: #d8dee9\">(6.6874785109966535, 1.3465666635682905)</code>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #4C566A\"># Let's run through it through the whole dataset</span></code></pre>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #81A1C1\">def</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">gradient_descent_runner</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9\">points</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #D8DEE9\">starting_m</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #D8DEE9\">starting_b</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #D8DEE9\">learning_rate</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #D8DEE9\">num_iterations</span><span style=\"color: #ECEFF4\">):</span>\n<span style=\"color: #D8DEE9FF\">    m </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> starting_m</span>\n<span style=\"color: #D8DEE9FF\">    b </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> starting_b</span>\n<span style=\"color: #D8DEE9FF\">    </span><span style=\"color: #81A1C1\">for</span><span style=\"color: #D8DEE9FF\"> i </span><span style=\"color: #81A1C1\">in</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">range</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">num_iterations</span><span style=\"color: #ECEFF4\">)</span><span style=\"color: #D8DEE9FF\">:</span>\n<span style=\"color: #D8DEE9FF\">        m, b </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">step_gradient</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">m</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> b</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> np.array</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">points</span><span style=\"color: #ECEFF4\">),</span><span style=\"color: #88C0D0\"> learning_rate</span><span style=\"color: #ECEFF4\">)</span>\n<span style=\"color: #D8DEE9FF\">    </span><span style=\"color: #81A1C1\">return</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">[</span><span style=\"color: #D8DEE9FF\">m, b</span><span style=\"color: #ECEFF4\">]</span></code></pre>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #D8DEE9FF\">number_iterations </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #B48EAD\">10000</span>\n<span style=\"color: #ECEFF4\">[</span><span style=\"color: #D8DEE9FF\">m, b</span><span style=\"color: #ECEFF4\">]</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">gradient_descent_runner</span><span style=\"color: #ECEFF4\">(</span>\n<span style=\"color: #88C0D0\">    data</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> </span>\n<span style=\"color: #88C0D0\">    m_guess</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> </span>\n<span style=\"color: #88C0D0\">    b_guess</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> </span>\n<span style=\"color: #88C0D0\">    learning_rate</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> </span>\n<span style=\"color: #88C0D0\">    number_iterations</span>\n<span style=\"color: #ECEFF4\">)</span></code></pre>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #88C0D0\">print</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #ECEFF4\">\"</span><span style=\"color: #A3BE8C\">Starting gradient descent at guess_m = </span><span style=\"color: #EBCB8B\">{0}</span><span style=\"color: #A3BE8C\">, guess_b = </span><span style=\"color: #EBCB8B\">{1}</span><span style=\"color: #ECEFF4\">\"</span><span style=\"color: #88C0D0\">.format</span><span style=\"color: #ECEFF4\">(</span>\n<span style=\"color: #88C0D0\">    m_guess</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> </span>\n<span style=\"color: #88C0D0\">    b_guess</span>\n<span style=\"color: #ECEFF4\">))</span>\n<span style=\"color: #88C0D0\">print</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #ECEFF4\">\"</span><span style=\"color: #A3BE8C\">Last gradient descent at guess_m = </span><span style=\"color: #EBCB8B\">{0}</span><span style=\"color: #A3BE8C\">, guess_b = </span><span style=\"color: #EBCB8B\">{1}</span><span style=\"color: #ECEFF4\">\"</span><span style=\"color: #88C0D0\">.format</span><span style=\"color: #ECEFF4\">(</span>\n<span style=\"color: #88C0D0\">    m</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> </span>\n<span style=\"color: #88C0D0\">    b</span>\n<span style=\"color: #ECEFF4\">))</span></code></pre>\n<code class=\"shiki\" style=\"background: #2e3440; color: #d8dee9\">Starting gradient descent at guess_m = 1.3450919020620442, guess_b = 6.687439682550092\nLast gradient descent at guess_m = 1.4510680203998683, guess_b = 1.4510195909326549</code>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #81A1C1\">def</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">compute_error_for_line</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9\">m</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #D8DEE9\">b</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #D8DEE9\">points</span><span style=\"color: #ECEFF4\">):</span>\n<span style=\"color: #D8DEE9FF\">    total_error </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #B48EAD\">0</span>\n<span style=\"color: #D8DEE9FF\">    </span><span style=\"color: #4C566A\"># sum (y_i - y_hat_i) ^ 2</span>\n<span style=\"color: #D8DEE9FF\">    </span><span style=\"color: #81A1C1\">for</span><span style=\"color: #D8DEE9FF\"> i </span><span style=\"color: #81A1C1\">in</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">range</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #B48EAD\">0</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> len</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">points</span><span style=\"color: #ECEFF4\">))</span><span style=\"color: #D8DEE9FF\">:</span>\n<span style=\"color: #D8DEE9FF\">        x </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> points</span><span style=\"color: #ECEFF4\">[</span><span style=\"color: #D8DEE9FF\">i, </span><span style=\"color: #B48EAD\">0</span><span style=\"color: #ECEFF4\">]</span>\n<span style=\"color: #D8DEE9FF\">        y </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> points</span><span style=\"color: #ECEFF4\">[</span><span style=\"color: #D8DEE9FF\">i, </span><span style=\"color: #B48EAD\">1</span><span style=\"color: #ECEFF4\">]</span>\n<span style=\"color: #D8DEE9FF\">        total_error </span><span style=\"color: #81A1C1\">+=</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9FF\">y </span><span style=\"color: #81A1C1\">-</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #D8DEE9FF\">m </span><span style=\"color: #81A1C1\">*</span><span style=\"color: #D8DEE9FF\"> x </span><span style=\"color: #81A1C1\">+</span><span style=\"color: #D8DEE9FF\"> b</span><span style=\"color: #ECEFF4\">))</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #81A1C1\">**</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #B48EAD\">2</span>\n<span style=\"color: #D8DEE9FF\">    </span><span style=\"color: #4C566A\"># 1 / n</span>\n<span style=\"color: #D8DEE9FF\">    mse </span><span style=\"color: #81A1C1\">=</span><span style=\"color: #D8DEE9FF\"> total_error </span><span style=\"color: #81A1C1\">/</span><span style=\"color: #D8DEE9FF\"> </span><span style=\"color: #88C0D0\">float</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">len</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">points</span><span style=\"color: #ECEFF4\">))</span>\n<span style=\"color: #D8DEE9FF\">    </span><span style=\"color: #81A1C1\">return</span><span style=\"color: #D8DEE9FF\"> mse</span></code></pre>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #4C566A\"># lets see how bad our guess was</span>\n\n<span style=\"color: #88C0D0\">compute_error_for_line</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">m_guess</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> b_guess</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> data.values</span><span style=\"color: #ECEFF4\">)</span></code></pre>\n<code class=\"shiki\" style=\"background: #2e3440; color: #d8dee9\">838.9099083602013</code>\n<pre class=\"shiki\" style=\"background-color: #2e3440\"><code><span style=\"color: #88C0D0\">print</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #ECEFF4\">\"</span><span style=\"color: #A3BE8C\">Starting gradient descent at </span><span style=\"color: #EBCB8B\">\\n</span><span style=\"color: #A3BE8C\"> guess_m = </span><span style=\"color: #EBCB8B\">{0}</span><span style=\"color: #A3BE8C\">, guess_b = </span><span style=\"color: #EBCB8B\">{1}</span><span style=\"color: #A3BE8C\">, error </span><span style=\"color: #EBCB8B\">{2}</span><span style=\"color: #ECEFF4\">\"</span><span style=\"color: #88C0D0\">.format</span><span style=\"color: #ECEFF4\">(</span>\n<span style=\"color: #88C0D0\">    m_guess</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> </span>\n<span style=\"color: #88C0D0\">    b_guess</span><span style=\"color: #ECEFF4\">,</span>\n<span style=\"color: #88C0D0\">    compute_error_for_line</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">m_guess</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> b_guess</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> data.values</span><span style=\"color: #ECEFF4\">)</span>\n<span style=\"color: #ECEFF4\">))</span>\n<span style=\"color: #88C0D0\">print</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #ECEFF4\">\"</span><span style=\"color: #A3BE8C\">Last gradient descent at </span><span style=\"color: #EBCB8B\">\\n</span><span style=\"color: #A3BE8C\"> guess_m = </span><span style=\"color: #EBCB8B\">{0}</span><span style=\"color: #A3BE8C\">, guess_b = </span><span style=\"color: #EBCB8B\">{1}</span><span style=\"color: #A3BE8C\">, error </span><span style=\"color: #EBCB8B\">{2}</span><span style=\"color: #ECEFF4\">\"</span><span style=\"color: #88C0D0\">.format</span><span style=\"color: #ECEFF4\">(</span>\n<span style=\"color: #88C0D0\">    m</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> </span>\n<span style=\"color: #88C0D0\">    b</span><span style=\"color: #ECEFF4\">,</span>\n<span style=\"color: #88C0D0\">    compute_error_for_line</span><span style=\"color: #ECEFF4\">(</span><span style=\"color: #88C0D0\">m</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> b</span><span style=\"color: #ECEFF4\">,</span><span style=\"color: #88C0D0\"> data.values</span><span style=\"color: #ECEFF4\">)</span>\n<span style=\"color: #ECEFF4\">))</span></code></pre>\n<code class=\"shiki\" style=\"background: #2e3440; color: #d8dee9\">Starting gradient descent at \n guess_m = 2, guess_b = 1, error 838.9099083602013\nLast gradient descent at \n guess_m = 1.4510680203998683, guess_b = 1.4510195909326549, error 111.87217648730648</code>\n<h1 id=\"how-does-gradient-descent-work\"><a href=\"#how-does-gradient-descent-work\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>How does gradient descent work?</h1>\n<hr>\n<p>In it's most general form:</p>\n<p>Gradient descent is based on the observation that if the multi-variable function ${\\displaystyle F(\\mathbf {x} )}$ is defined and differentiable in a neighborhood of a point ${\\displaystyle \\mathbf {a} }$ , then ${\\displaystyle F(\\mathbf {x} )}$ decreases fastest if one goes from ${\\displaystyle \\mathbf {a} }$  in the direction of the negative gradient of ${\\displaystyle F}$ at ${\\displaystyle,-\\nabla F(\\mathbf {a} )}$. It follows that, if</p>\n<p>${\\displaystyle \\mathbf {a} <em>{n+1}=\\mathbf {a} </em>{n}-\\gamma \\nabla F(\\mathbf {a} _{n})}$</p>\n<p>for ${\\displaystyle \\gamma \\in \\mathbb {R} <em>{+}}$ small enough, then ${\\displaystyle F(\\mathbf {a</em>{n}} )\\geq F(\\mathbf {a_{n+1}} )}$. In other words, the term ${\\displaystyle \\gamma \\nabla F(\\mathbf {a} )}$ is subtracted from ${\\displaystyle \\mathbf {a} }$  because we want to move against the gradient, toward the minimum.</p>\n<p>Here we have defined and the algorith works with contraints:</p>\n<p><strong>learning rate</strong> ${\\gamma}$, for small ${\\displaystyle \\gamma \\in \\mathbb {R} _{+}}$</p>\n<p><strong>function</strong> $F(\\mathbf{x})$,  if differentiable; then ${\\displaystyle F(\\mathbf {a<em>{n}} )\\geq F(\\mathbf {a</em>{n+1}} )}$</p>\n<p><strong>Leading to</strong> ($\\leadsto $) a monotonic sequence $F(\\mathbf {x} <em>{0})\\geq F(\\mathbf {x} </em>{1})\\geq F(\\mathbf {x} _{2})\\geq \\cdots,$</p>\n<h1 id=\"coming-back-to-the-real-world\"><a href=\"#coming-back-to-the-real-world\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Coming back to the real world</h1>\n<p>Scikit learn provides you two approaches to linear regression:</p>\n<p>If you can decompose your loss function into additive terms, then stochastic approach is known to behave better (thus SGD) and if you can spare enough memory - OLS method is faster and easier (thus first solution).</p>\n<p>1) <code class=\"shiki-inline\" style=\"background: #2e3440; color: #d8dee9\">LinearRegression</code> object uses <strong>Ordinary Least Squares</strong> solver from scipy, as LR is one of two classifiers which have closed form solution. Despite the ML course - you can actually learn this model by just inverting and multiplicating some matrices.</p>\n<p>2) <code class=\"shiki-inline\" style=\"background: #2e3440; color: #d8dee9\">SGDRegressor</code> which is an implementation of <strong>stochastic gradient descent</strong>, very generic one where you can choose your penalty terms. To obtain linear regression you choose loss to be L2 and penalty also to none (linear regression) or L2 (Ridge regression)</p>\n<p>The \"gradient descent\" is a major part of most learning algorithm. What you will see most often is a improved version of the algorithm <strong>Stochastic Gradient Descent</strong>.</p>\n<p>source - <a href=\"https://stackoverflow.com/questions/34469237/linear-regression-and-gradient-descent-in-scikit-learn-pandas\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">linear regression scitkit</a></p>\n"}}]}}},"context":{}}